 
@InProceedings{Evensky1999,
  author    = {Evensky, David A. and Gentile, Ann C. and Wyckoff, Pete and Armstrong, Robert C.},
  booktitle = {Distributed {Applications} and {Interoperable} {Systems} {II}},
  title     = {The {Lilith} {Framework} for the {Rapid} {Development} of {Secure} {Scalable} {Tools} for {Distributed} {Computing}},
  year      = {1999},
  address   = {Boston, MA},
  editor    = {Kutvonen, Lea and König, Hartmut and Tienari, Martti},
  pages     = {163--168},
  publisher = {Springer US},
  series    = {{IFIP} — {The} {International} {Federation} for {Information} {Processing}},
  abstract  = {Lilith is a general purpose framework written in Java, that provides a highly scalable distribution of user code across a heterogeneous computing platform. By creation of suitable user code, the Lilith framework can be used for tool development. Lilith promotes rapid development since it handles all the details of code distribution and communication, while the user code need only define the tool functionality on a single node, in accordance with a simple API. The scalable performance provided by Lilith is crucial to the production of time-effective tools for large distributed systems. This time-efficiency, however, allows both constructive and destructive tasks to be accomplished quickly; therefore, security is a concern. We present the Lilith API and a prototype example of the usage of Lilith in distributed computing and we discuss the security model, which is currently under design.},
  doi       = {10.1007/978-0-387-35565-8_12},
  file      = {Full Text PDF:https\://link.springer.com/content/pdf/10.1007%2F978-0-387-35565-8_12.pdf:application/pdf},
  isbn      = {9780387355658},
  keywords  = {Scalable tools, secure tools, frameworks, distributed computing},
  language  = {en},
}

 
@InProceedings{Hou2017,
  author    = {Hou, Lu and Lei, Lei and Zheng, Kan},
  booktitle = {2017 {IEEE} {Globecom} {Workshops} ({GC} {Wkshps})},
  title     = {Design on {Publish}/{Subscribe} {Message} {Dissemination} for {Vehicular} {Networks} with {Mobile} {Edge} {Computing}},
  year      = {2017},
  month     = dec,
  pages     = {1--6},
  abstract  = {The safety messages in vehicular networks require to be transmitted as fast as possible. On the other hand, the high mobility of vehicles poses an other major challenge on efficient message disseminations. In this paper, we present a design on publish/subscribe message dissemination (DPSMD) for vehicular networks with Mobile Edge Computing (MEC). Our design consists of message brokers that provide message exchange services, message handlers that excavate the potential value of messages and message hubs that bridge different parts of the system. MEC can be made use of in DPSMD to provide low-latency message services for vehicle users, while wide- area message disseminations are also well supported. The detailed descriptions is then given, including topic designs, subscription, publishing processes and message validating. Finally, a testbed is built up to evaluate the performance of the DPSMD in terms of the average time of message distributions.},
  doi       = {10.1109/GLOCOMW.2017.8269200},
  file      = {:Hou2017 - Design on Publish_Subscribe Message Dissemination for Vehicular Networks with Mobile Edge Computing.pdf:PDF},
  keywords  = {Servers, Cloud computing, Mobile computing, Mobile communication, Edge computing, Safety, Bridges},
}

 
@Article{Huang2018,
  author     = {Huang, Xumin and Yu, Rong and Liu, Jianqi and Shu, Lei},
  journal    = {IEEE Access},
  title      = {Parked {Vehicle} {Edge} {Computing}: {Exploiting} {Opportunistic} {Resources} for {Distributed} {Mobile} {Applications}},
  year       = {2018},
  issn       = {2169-3536},
  pages      = {66649--66663},
  volume     = {6},
  abstract   = {Vehicular Edge Computing (VEC) has been studied as an important application of mobile edge computing in vehicular networks. Usually, the generalization of VEC involves large-scale deployment of dedicated servers, which will cause tremendous economic expense. We also observe that the Parked Vehicles (PVs) in addition to mobile vehicles have rich and underutilized resources for task execution in vehicular networks. Thus, we consider scheduling PVs as available edge computing nodes to execute tasks, and this leads to a new computing paradigm, called by parked vehicle edge computing (PVEC). In this paper, we investigate PVEC and explore opportunistic resources from PVs to run distributed mobile applications. PVs coordinate with VEC servers for collective task execution. First, a system architecture with primary network entities is proposed for enabling PVEC. We also elaborately design an interactive protocol to support mutual communications among them with security guarantee. Moreover, we measure the availability of opportunistic resources and formulate a resource scheduling optimization problem by using Stackelberg game approach. A subgradient-based iterative algorithm is presented to determine workload allocation among PVs and minimize the overall cost of users. Numerical results indicate that compared with existing schemes, PVEC serves more vehicles and reduces service fee for users. We also demonstrate that the Stackelberg game approach is effective and efficient.},
  doi        = {10.1109/ACCESS.2018.2879578},
  file       = {:Huang2018 - Parked Vehicle Edge Computing_ Exploiting Opportunistic Resources for Distributed Mobile Applications.pdf:PDF},
  keywords   = {Servers, Task analysis, Edge computing, Mobile applications, Protocols, Processor scheduling, Systems architecture, intelligent vehicles, computational efficiency, resource management},
  shorttitle = {Parked {Vehicle} {Edge} {Computing}},
}

 
@InProceedings{Maharjan2020,
  author    = {Maharjan, Amir Man Singh and Elchouemi, Amr},
  booktitle = {2020 5th {International} {Conference} on {Innovative} {Technologies} in {Intelligent} {Systems} and {Industrial} {Applications} ({CITISIA})},
  title     = {Smart {Parking} {Utilizing} {IoT} {Embedding} {Fog} {Computing} {Based} on {Smart} {Parking} {Architecture}},
  year      = {2020},
  month     = nov,
  pages     = {1--9},
  abstract  = {Rapid population growth and skyrocketing demand of private transportation bloom the market of automakers worldwide. The concept of automated parking system under smart city arises with the availability of the technology like fast internet connections, offloading computational resources, IoT devices communicating various devices each other, to uplift the quality of life. Revolution of cloud computing and ease of this technology also open the door for better opportunities for smart parking where a system can be served from the remote area, but there is an issue with cloud computing for cost of operation and latency of the services. In urban cities there is rapid growth of population and there is advancement of automotive industries, there are lots of vehicles that are being used in all the cities which creates a lot of issues like road congestions, issue in parking spaces. This paper proposes the fog computing architecture to reduce the latency and efficiently utilise all the available technologies together by building fog computing architecture network which is a multi-tier structure where applications runs jointly, communicates and compute with each other. Smart parking has gain massive attention due to ease and outcome from those technologies are exponential. The role of Internet of Things and fog computing enable the platform to minimize the take duration for finding the parking space, this reduces the time and excess use of fuel and emission of CO2, these are the consequence of over and unmanaged vehicles in the urban areas and unmanaged parking areas.},
  doi       = {10.1109/CITISIA50690.2020.9371848},
  file      = {:Maharjan2020 - Smart Parking Utilizing IoT Embedding Fog Computing Based on Smart Parking Architecture.pdf:PDF},
  keywords  = {Space vehicles, Cloud computing, Sociology, Computer architecture, Internet of Things, Statistics, Edge computing, Fog computing architecture, IoT, smart city, smart parking},
}

 
@Article{Wu2021,
  author   = {Wu, Yalan and Wu, Jigang and Chen, Long and Zhou, Gangqiang and Yan, Jiaquan},
  journal  = {IEEE Transactions on Intelligent Transportation Systems},
  title    = {Fog {Computing} {Model} and {Efficient} {Algorithms} for {Directional} {Vehicle} {Mobility} in {Vehicular} {Network}},
  year     = {2021},
  issn     = {1558-0016},
  month    = may,
  number   = {5},
  pages    = {2599--2614},
  volume   = {22},
  abstract = {Vehicular fog computing (VFC) has become an appealing paradigm to provide services for vehicles and traffic systems. However, high mobility is one of the great challenges to the communication and computation service qualities in VFC. A network model for directional vehicle mobility is proposed in this paper to guarantee the service qualities of vehicles in VFC. In the model, vehicles are configured into three vehicular subnetworks according to their turning directions at the next crossing. For each subnetwork, vehicles communicate with each other via vehicle-to-vehicle communication, and with roadside units via vehicle-to-infrastructure communication. The aim is to minimize the average response time of the tasks originated from vehicles. By carefully choosing neighboring vehicles as task processing helpers, a greedy algorithm is proposed to solve the mentioned optimization problem. Besides, two bipartite matching based algorithms, named BMA1 and BMA2, are proposed by exploiting Kuhn-Munkras approach and minimum-cost maximum-flow approach, respectively. Performance of the proposed model and the offloading algorithms are evaluated on the combined simulation platform by open street map, SUMO and NS-3. Simulation results show that, the proposed model outperforms four existing models in terms of average response time, when the five models have similar number of unsuccessful tasks. Moreover, the proposed BMA1 and BMA2 are superior to the existing greedy algorithm in terms of the average response time of tasks, and the proposed greedy algorithm significantly accelerates the generation of offloading decisions in comparison to BMA1, BMA2 and the existing greedy algorithm.},
  doi      = {10.1109/TITS.2020.2971343},
  file     = {:Wu2021 - Fog Computing Model and Efficient Algorithms for Directional Vehicle Mobility in Vehicular Network.pdf:PDF},
  keywords = {Computational modeling, Task analysis, Time factors, Greedy algorithms, Roads, Edge computing, Handover, Vehicular fog computing, vehicular network, task offloading, algorithm},
}

 
@Article{Huang2020,
  author   = {Huang, Xumin and Ye, Dongdong and Yu, Rong and Shu, Lei},
  journal  = {IEEE/CAA Journal of Automatica Sinica},
  title    = {Securing parked vehicle assisted fog computing with blockchain and optimal smart contract design},
  year     = {2020},
  issn     = {2329-9274},
  month    = mar,
  number   = {2},
  pages    = {426--441},
  volume   = {7},
  abstract = {Vehicular fog computing ( VFC ) has been envisioned as an important application of fog computing in vehicular networks. Parked vehicles with embedded computation resources could be exploited as a supplement for VFC. They cooperate with fog servers to process offloading requests at the vehicular network edge, leading to a new paradigm called parked vehicle assisted fog computing ( PVFC ) . However, each coin has two sides. There is a follow-up challenging issue in the distributed and trustless computing environment. The centralized computation offloading without tamper-proof audit causes security threats. It could not guard against false-reporting, free-riding behaviors, spoofing attacks and repudiation attacks. Thus, we leverage the blockchain technology to achieve decentralized PVFC. Request posting, workload undertaking, task evaluation and reward assignment are organized and validated automatically through smart contract executions. Network activities in computation offloading become transparent, verifiable and traceable to eliminate security risks. To this end, we introduce network entities and design interactive smart contract operations across them. The optimal smart contract design problem is formulated and solved within the Stackelberg game framework to minimize the total payments for users. Security analysis and extensive numerical results are provided to demonstrate that our scheme has high security and efficiency guarantee.},
  doi      = {10.1109/JAS.2020.1003039},
  file     = {:Huang2020 - Securing Parked Vehicle Assisted Fog Computing with Blockchain and Optimal Smart Contract Design.pdf:PDF},
  keywords = {Contracts, Servers, Task analysis, Edge computing, Games},
}

 
@InProceedings{Chun2016,
  author    = {Chun, Sejin and Shin, Sangjin and Seo, Seungmin and Eom, Sungkwang and Jung, Jooik and Lee, Kyong-Ho},
  booktitle = {2016 {IEEE} {International} {Conference} on {Cloud} {Computing} {Technology} and {Science} ({CloudCom})},
  title     = {A {Pub}/{Sub}-{Based} {Fog} {Computing} {Architecture} for {Internet}-of-{Vehicles}},
  year      = {2016},
  month     = dec,
  note      = {ISSN: 2330-2186},
  pages     = {90--93},
  abstract  = {Fog computing is a promising paradigm in terms of extending cloud computing to an edge network. In a broad sense, fog computing in Internet-of-Vehicles(IoV) provides low-latency services since fog nodes are closely located with moving cars and are locally distributed. In this paper, we propose a fog computing architecture based on a publish/subscribe model. After that, we describe a traffic congestion control scenario using a smart traffic light system which operates on top of the proposed architecture. Furthermore, we propose an upper-level domain ontology in order to enhance the expressivity of knowledge and describe a variety of semantic properties which interlink spatial information in IoV. Finally, we present an active rule where supports the exchange of event-driven messages between publishing and subscribing fog nodes.},
  doi       = {10.1109/CloudCom.2016.0029},
  file      = {:Chun2016 - A Pub_Sub Based Fog Computing Architecture for Internet of Vehicles.pdf:PDF},
  issn      = {2330-2186},
  keywords  = {Decision support systems, Conferences, Cloud computing, Semantic Web, Computers, Edge computing, Internet-of-Vehicles, Internet-of-Cars, Fog computing, OWL, Pub/Sub system},
}

 
@InProceedings{Saito2021,
  author    = {Saito, Takumi and Nakamura, Shigenari and Enokido, Tomoya and Takizawa, Makoto},
  booktitle = {Complex, {Intelligent} and {Software} {Intensive} {Systems}},
  title     = {A {Topic}-{Based} {Publish}/{Subscribe} {System} in a {Fog} {Computing} {Model} for the {IoT}},
  year      = {2021},
  address   = {Cham},
  editor    = {Barolli, Leonard and Poniszewska-Maranda, Aneta and Enokido, Tomoya},
  pages     = {12--21},
  publisher = {Springer International Publishing},
  series    = {Advances in {Intelligent} {Systems} and {Computing}},
  abstract  = {In order to reduce the traffic of networks and servers in the IoT, types of the fog computing (FC) models are proposed, which are composed of fog nodes. A fog node supports application processes to calculate output data on sensor data and forward the output data to servers. A topic-based PS (publish/subscribe) model is a new contents-aware, event-driven model of a distributed system. Here, a process publishes a message whose contents are denoted by publication topics. A process specifies subscription topics and only is delivered messages whose publication topics include some of the subscription topics. In our previous studies, the MPSFC (Mobile PS (publish/subscribe) Fog Computing) model is proposed where mobile fog nodes like vehicles are interconnected and fog nodes communicate with one another in wireless networks by the PS model. In this paper, we propose a TBDT (Topic-based Data Transmission) protocol for mobile fog nodes to deliver messages to target nodes. In the evaluation, we show the number of messages in the TBDT protocol is fewer than the epidemic routing protocol while the delivery ratio is smaller.},
  doi       = {10.1007/978-3-030-50454-0_2},
  file      = {:Saito2021 - A Topic Based Publish_Subscribe System in a Fog Computing Model for the IoT.pdf:PDF},
  isbn      = {9783030504540},
  keywords  = {IoT, Fog Computing (FC) model, Mobile Fog Computing (MFC) model, Topic-based publish/subscribe system, Mobile Publish/Subscribe Fog Computing (MPSFC) model},
  language  = {en},
}

 
@Article{Liu2019,
  author     = {Liu, Shaoshan and Liu, Liangkai and Tang, Jie and Yu, Bo and Wang, Yifan and Shi, Weisong},
  journal    = {Proceedings of the IEEE},
  title      = {Edge {Computing} for {Autonomous} {Driving}: {Opportunities} and {Challenges}},
  year       = {2019},
  issn       = {1558-2256},
  month      = aug,
  number     = {8},
  pages      = {1697--1716},
  volume     = {107},
  abstract   = {Safety is the most important requirement for autonomous vehicles; hence, the ultimate challenge of designing an edge computing ecosystem for autonomous vehicles is to deliver enough computing power, redundancy, and security so as to guarantee the safety of autonomous vehicles. Specifically, autonomous driving systems are extremely complex; they tightly integrate many technologies, including sensing, localization, perception, decision making, as well as the smooth interactions with cloud platforms for high-definition (HD) map generation and data storage. These complexities impose numerous challenges for the design of autonomous driving edge computing systems. First, edge computing systems for autonomous driving need to process an enormous amount of data in real time, and often the incoming data from different sensors are highly heterogeneous. Since autonomous driving edge computing systems are mobile, they often have very strict energy consumption restrictions. Thus, it is imperative to deliver sufficient computing power with reasonable energy consumption, to guarantee the safety of autonomous vehicles, even at high speed. Second, in addition to the edge system design, vehicle-to-everything (V2X) provides redundancy for autonomous driving workloads and alleviates stringent performance and energy constraints on the edge side. With V2X, more research is required to define how vehicles cooperate with each other and the infrastructure. Last, safety cannot be guaranteed when security is compromised. Thus, protecting autonomous driving edge computing systems against attacks at different layers of the sensing and computing stack is of paramount concern. In this paper, we review state-of-the-art approaches in these areas as well as explore potential solutions to address these challenges.},
  doi        = {10.1109/JPROC.2019.2915983},
  file       = {:Liu2019 - Edge Computing for Autonomous Driving_ Opportunities and Challenges.pdf:PDF},
  keywords   = {Autonomous vehicles, Edge computing, Sensors, Real-time systems, Vehicle-to-everything, Safety, Global navigation satellite system, Connected and autonomous vehicles (CAVs), edge computing, heterogeneous computing, security, vehicle-to-everything (V2X), vehicular operating system},
  shorttitle = {Edge {Computing} for {Autonomous} {Driving}},
}

 
@Article{Hou2016,
  author     = {Hou, Xueshi and Li, Yong and Chen, Min and Wu, Di and Jin, Depeng and Chen, Sheng},
  journal    = {IEEE Transactions on Vehicular Technology},
  title      = {Vehicular {Fog} {Computing}: {A} {Viewpoint} of {Vehicles} as the {Infrastructures}},
  year       = {2016},
  issn       = {1939-9359},
  month      = jun,
  number     = {6},
  pages      = {3860--3873},
  volume     = {65},
  abstract   = {With the emergence of ever-growing advanced vehicular applications, the challenges to meet the demands from both communication and computation are increasingly prominent. Without powerful communication and computational support, various vehicular applications and services will still stay in the concept phase and cannot be put into practice in the daily life. Thus, solving this problem is of great importance. The existing solutions, such as cellular networks, roadside units (RSUs), and mobile cloud computing, are far from perfect because they highly depend on and bear the cost of additional infrastructure deployment. Given tremendous number of vehicles in urban areas, putting these underutilized vehicular resources into use offers great opportunity and value. Therefore, we conceive the idea of utilizing vehicles as the infrastructures for communication and computation, named vehicular fog computing (VFC), which is an architecture that utilizes a collaborative multitude of end-user clients or near-user edge devices to carry out communication and computation, based on better utilization of individual communication and computational resources of each vehicle. By aggregating abundant resources of individual vehicles, the quality of services and applications can be enhanced greatly. In particular, by discussing four types of scenarios of moving and parked vehicles as the communication and computational infrastructures, we carry on a quantitative analysis of the capacities of VFC. We unveil an interesting relationship among the communication capability, connectivity, and mobility of vehicles, and we also find out the characteristics about the pattern of parking behavior, which benefits from the understanding of utilizing the vehicular resources. Finally, we discuss the challenges and open problems in implementing the proposed VFC system as the infrastructures. Our study provides insights for this novel promising paradigm, as well as research topics about vehicular information infrastructures.},
  doi        = {10.1109/TVT.2016.2532863},
  file       = {:Hou2016 - Vehicular Fog Computing_ a Viewpoint of Vehicles As the Infrastructures.pdf:PDF},
  keywords   = {Vehicles, Cloud computing, Computer architecture, Mobile communication, Mobile computing, Real-time systems, Urban areas, Vehicular fog computing, infrastructures, cloud computing, vehicular network, vehicular fog computing (VFC)},
  shorttitle = {Vehicular {Fog} {Computing}},
}

 
@Article{Liu2019a,
  author   = {Liu, Yi and Yu, Huimin and Xie, Shengli and Zhang, Yan},
  journal  = {IEEE Transactions on Vehicular Technology},
  title    = {Deep {Reinforcement} {Learning} for {Offloading} and {Resource} {Allocation} in {Vehicle} {Edge} {Computing} and {Networks}},
  year     = {2019},
  issn     = {1939-9359},
  month    = nov,
  number   = {11},
  pages    = {11158--11168},
  volume   = {68},
  abstract = {Mobile Edge Computing (MEC) is a promising technology to extend the diverse services to the edge of Internet of Things (IoT) system. However, the static edge server deployment may cause “service hole” in IoT networks in which the location and service requests of the User Equipments (UEs) may be dynamically changing. In this paper, we firstly explore a vehicle edge computing network architecture in which the vehicles can act as the mobile edge servers to provide computation services for nearby UEs. Then, we propose as vehicle-assisted offloading scheme for UEs while considering the delay of the computation task. Accordingly, an optimization problem is formulated to maximize the long-term utility of the vehicle edge computing network. Considering the stochastic vehicle traffic, dynamic computation requests and time-varying communication conditions, the problem is further formulated as a semi-Markov process and two reinforcement learning methods: Q-learning based method and deep reinforcement learning (DRL) method, are proposed to obtain the optimal policies of computation offloading and resource allocation. Finally, we analyze the effectiveness of the proposed scheme in the vehicular edge computing network by giving numerical results.},
  doi      = {10.1109/TVT.2019.2935450},
  file     = {:Liu2019a - Deep Reinforcement Learning for Offloading and Resource Allocation in Vehicle Edge Computing and Networks.pdf:PDF},
  keywords = {Task analysis, Edge computing, Servers, Internet of Things, Computational modeling, Iron, Reinforcement learning, Vehicle edge computing, resource allocation, IoT, deep reinforcement learning},
}

 
@Article{Perez2022,
  author   = {Pérez, Jorge and Díaz, Jessica and Berrocal, Javier and López-Viana, Ramón and González-Prieto, Ángel},
  journal  = {Computing},
  title    = {Edge computing},
  year     = {2022},
  issn     = {1436-5057},
  month    = jul,
  abstract = {IoT edge computing is a new computing paradigm “in the IoT domain” for performing calculations and processing at the edge of the network, closer to the user and the source of the data. This paradigm is relatively recent, and, together with cloud and fog computing, there may be some confusion about its meaning and implications. This paper aims to help practitioners and researchers better understand what the industry thinks about what IoT edge computing is, and the expected benefits and challenges associated with this paradigm. We conducted a survey using a semi-structured in-depth questionnaire to collect qualitative data from relevant stakeholders from 29 multinational companies and qualitatively analyzed these data using the Constructivist Grounded Theory (Charmaz) method. Several researchers participated in the coding process (collaborative coding). To ensure consensus on the constructs that support the theory and thus improve the rigor of qualitative research, we conducted an intercoder agreement analysis. From the analysis, we have derived a substantive and analytic theory of what companies perceive about IoT edge computing, its benefits and challenges. The theory is substantive in that the scope of validity refers to the 29 surveys processed and analytic in that it analyzes “what is” rather than explaining causality or attempting predictive generalizations. A public repository with all the data related to the information capture process and the products resulting from the analysis of this information is publicly available. This study aims to strengthen the evidence and support practitioners in making better informed decisions about why companies are adopting edge computing and the current challenges they face. Additionally, the testing theory phase shows that the results are aligned with the ISO/IEC TR 30164 standard.},
  doi      = {10.1007/s00607-022-01104-2},
  file     = {Full Text PDF:https\://link.springer.com/content/pdf/10.1007%2Fs00607-022-01104-2.pdf:application/pdf},
  keywords = {Edge Computing, IoT, Grounded Theory, Inter-rater Reliability, Inter-rater Agreement, 68-02, 68Qxx},
  language = {en},
  url      = {https://doi.org/10.1007/s00607-022-01104-2},
  urldate  = {2022-10-11},
}

 
@InProceedings{Varghese2016,
  author    = {Varghese, Blesson and Wang, Nan and Barbhuiya, Sakil and Kilpatrick, Peter and Nikolopoulos, Dimitrios S.},
  booktitle = {2016 {IEEE} {International} {Conference} on {Smart} {Cloud} ({SmartCloud})},
  title     = {Challenges and {Opportunities} in {Edge} {Computing}},
  year      = {2016},
  month     = nov,
  pages     = {20--26},
  abstract  = {Many cloud-based applications employ a data centers as a central server to process data that is generated by edge devices, such as smartphones, tablets and wearables. This model places ever increasing demands on communication and computational infrastructure with inevitable adverse effect on Quality-of-Service and Experience. The concept of Edge Computing is predicated on moving some of this computational load towards the edge of the network to harness computational capabilities that are currently untapped in edge nodes, such as base stations, routers and switches. This position paper considers the challenges and opportunities that arise out of this new direction in the computing landscape.},
  doi       = {10.1109/SmartCloud.2016.18},
  keywords  = {Cloud computing, Base stations, Performance evaluation, Servers, Hardware, Smart phones, edge computing, fog computing, edge nodes, distributed computing, cloud, cloudlet},
}

 
@Article{Shi2016,
  author     = {Shi, Weisong and Cao, Jie and Zhang, Quan and Li, Youhuizi and Xu, Lanyu},
  journal    = {IEEE Internet of Things Journal},
  title      = {Edge {Computing}: {Vision} and {Challenges}},
  year       = {2016},
  issn       = {2327-4662},
  month      = oct,
  number     = {5},
  pages      = {637--646},
  volume     = {3},
  abstract   = {The proliferation of Internet of Things (IoT) and the success of rich cloud services have pushed the horizon of a new computing paradigm, edge computing, which calls for processing the data at the edge of the network. Edge computing has the potential to address the concerns of response time requirement, battery life constraint, bandwidth cost saving, as well as data safety and privacy. In this paper, we introduce the definition of edge computing, followed by several case studies, ranging from cloud offloading to smart home and city, as well as collaborative edge to materialize the concept of edge computing. Finally, we present several challenges and opportunities in the field of edge computing, and hope this paper will gain attention from the community and inspire more research in this direction.},
  doi        = {10.1109/JIOT.2016.2579198},
  file       = {:Shi2016 - Edge Computing_ Vision and Challenges.pdf:PDF},
  keywords   = {Cloud computing, Internet of things, Bandwidth, Time factors, Mobile handsets, Data privacy, Smart homes, Edge computing, Internet of Things (IoT), smart home and city},
  shorttitle = {Edge {Computing}},
}

 
@TechReport{Liu2020,
  author     = {Liu, Liangkai and Lu, Sidi and Zhong, Ren and Wu, Baofu and Yao, Yongtao and Zhang, Qingyang and Shi, Weisong},
  title      = {Computing {Systems} for {Autonomous} {Driving}: {State}-of-the-{Art} and {Challenges}},
  year       = {2020},
  month      = dec,
  note       = {arXiv:2009.14349 [cs] type: article},
  abstract   = {The recent proliferation of computing technologies (e.g., sensors, computer vision, machine learning, and hardware acceleration), and the broad deployment of communication mechanisms (e.g., DSRC, C-V2X, 5G) have pushed the horizon of autonomous driving, which automates the decision and control of vehicles by leveraging the perception results based on multiple sensors. The key to the success of these autonomous systems is making a reliable decision in real-time fashion. However, accidents and fatalities caused by early deployed autonomous vehicles arise from time to time. The real traffic environment is too complicated for current autonomous driving computing systems to understand and handle. In this paper, we present state-of-the-art computing systems for autonomous driving, including seven performance metrics and nine key technologies, followed by twelve challenges to realize autonomous driving. We hope this paper will gain attention from both the computing and automotive communities and inspire more research in this direction.},
  annote     = {Comment: Accepted to IEEE Internet of Things Journal (19 pages, 2 figures, 4 tables)},
  file       = {:Liu2020 - Computing Systems for Autonomous Driving_ State of the Art and Challenges.pdf:PDF},
  keywords   = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Robotics},
  school     = {arXiv},
  shorttitle = {Computing {Systems} for {Autonomous} {Driving}},
  url        = {http://arxiv.org/abs/2009.14349},
  urldate    = {2022-10-19},
}

 
@InProceedings{Qian2009,
  author     = {Qian, Ling and Luo, Zhiguo and Du, Yujian and Guo, Leitao},
  booktitle  = {Cloud {Computing}},
  title      = {Cloud {Computing}: {An} {Overview}},
  year       = {2009},
  address    = {Berlin, Heidelberg},
  editor     = {Jaatun, Martin Gilje and Zhao, Gansen and Rong, Chunming},
  pages      = {626--631},
  publisher  = {Springer},
  series     = {Lecture {Notes} in {Computer} {Science}},
  abstract   = {In order to support the maximum number of user and elastic service with the minimum resource, the Internet service provider invented the cloud computing. within a few years, emerging cloud computing has became the hottest technology. From the publication of core papers by Google since 2003 to the commercialization of Amazon EC2 in 2006, and to the service offering of AT\&T Synaptic Hosting, the cloud computing has been evolved from internal IT system to public service, from cost-saving tools to revenue generator, and from ISP to telecom. This paper introduces the concept, history, pros and cons of cloud computing as well as the value chain and standardization effort.},
  doi        = {10.1007/978-3-642-10665-1_63},
  file       = {Full Text PDF:https\://link.springer.com/content/pdf/10.1007%2F978-3-642-10665-1_63.pdf:application/pdf},
  isbn       = {9783642106651},
  keywords   = {Cloud computing, Cloud Storage, Virtualization},
  language   = {en},
  shorttitle = {Cloud {Computing}},
}

 
@InCollection{Sunyaev2020,
  author    = {Sunyaev, Ali},
  publisher = {Springer International Publishing},
  title     = {Cloud {Computing}},
  year      = {2020},
  address   = {Cham},
  editor    = {Sunyaev, Ali},
  isbn      = {9783030349578},
  pages     = {195--236},
  abstract  = {Cloud computing is an evolution of information technology and a dominant business model for delivering IT resources. With cloud computing, individuals and organizations can gain on-demand network access to a shared pool of managed and scalable IT resources, such as servers, storage, and applications. Recently, academics as well as practitioners have paid a great deal of attention to cloud computing. We rely heavily on cloud services in our daily lives, e.g., for storing data, writing documents, managing businesses, and playing games online. Cloud computing also provides the infrastructure that has powered key digital trends such as mobile computing, the Internet of Things, big data, and artificial intelligence, thereby accelerating industry dynamics, disrupting existing business models, and fueling the digital transformation. Still, cloud computing not only provides a vast number of benefits and opportunities; it also comes with several challenges and concerns, e.g., regarding protecting customers’ data.},
  doi       = {10.1007/978-3-030-34957-8_7},
  file      = {:Sunyaev2020 - Cloud Computing.pdf:PDF},
  language  = {en},
  url       = {https://doi.org/10.1007/978-3-030-34957-8_7},
  urldate   = {2022-10-24},
}

 
@Article{Ibrahim2021,
  author     = {Ibrahim, Ibrahim Mahmood and Al, Et},
  journal    = {Turkish Journal of Computer and Mathematics Education (TURCOMAT)},
  title      = {Task {Scheduling} {Algorithms} in {Cloud} {Computing}: {A} {Review}},
  year       = {2021},
  issn       = {1309-4653},
  month      = apr,
  number     = {4},
  pages      = {1041--1053},
  volume     = {12},
  abstract   = {Cloud computing is the requirement based on clients and provides many resources that aim to share it as a service through the internet. For optimal use, Cloud computing resources such as storage, application, and other services need managing and scheduling these services. The principal idea behind the scheduling is to minimize loss time, workload, and maximize throughput. So, the scheduling task is essential to achieve accuracy and correctness on task completion. This paper gives an idea about various task scheduling algorithms in the cloud computing environment used by researchers. Finally, many authors applied different parameters like completion time, throughput, and cost to evaluate the system.},
  copyright  = {Copyright (c) 2021},
  doi        = {10.17762/turcomat.v12i4.612},
  file       = {:Ibrahim2021 - Task Scheduling Algorithms in Cloud Computing_ a Review.pdf:PDF},
  language   = {en},
  shorttitle = {Task {Scheduling} {Algorithms} in {Cloud} {Computing}},
  url        = {https://turcomat.org/index.php/turkbilmat/article/view/612},
  urldate    = {2022-10-24},
}

 
@InProceedings{MadeWirawan2018,
  author    = {Made Wirawan, I and Dwi Wahyono, Irawan and Idfi, Gilang and Radityo Kusumo, Gradiyanto},
  booktitle = {2018 {International} {Seminar} on {Application} for {Technology} of {Information} and {Communication}},
  title     = {{IoT} {Communication} {System} {Using} {Publish}-{Subscribe}},
  year      = {2018},
  month     = sep,
  pages     = {61--65},
  abstract  = {The development of the Internet of Thing (IoT) application has been very rapid in recent years. Research on IoT optimization continues to be done due to limited IoT resources. This research develops a river condition monitoring system for early warning using IoT with the Publish-Subscribe, communication model. Publisher as the sender of the river and Subscriber condition data as an application used to monitor river condition in the form of video data. The IoT Communication Model developed is the Adaptive Method. The use of the Adaptive method is due to continuous data changes and accepted by the user as monitoring data. An adaptive method is used to make efficient use of IoT resource due to big video data. Test results in this study indicate that the average efficiency of IoT resources is 34.7\%.},
  doi       = {10.1109/ISEMANTIC.2018.8549814},
  file      = {:MadeWirawan2018 - IoT Communication System Using Publish Subscribe.pdf:PDF},
  keywords  = {Monitoring, Publish-subscribe, Internet of Things, 3G mobile communication, Bandwidth, Publishing, Adaptation models, IoT, monitoring, publish-subscribe},
}

 
@TechReport{Mokhtarian2020,
  author   = {Mokhtarian, Armin and Kampmann, Alexandru and Alrifaee, Bassam and Kowalewski, Stefan},
  title    = {The {Dynamic} {Service}-oriented {Software} {Architecture} for the {UNICARagil} {Project}},
  year     = {2020},
  abstract = {Mokhtarian, Armin; Kampmann, Alexandru; Alrifaee, Bassam; Kowalewski, Stefan},
  doi      = {10.18154/RWTH-2020-11256},
  language = {de},
  school   = {Institute for Automotive Engineering, RWTH Aachen University ; Aachen : Institute for Combustion Engines, RWTH Aachen University},
  url      = {https://publications.rwth-aachen.de/record/807282},
  urldate  = {2022-10-25},
}

 
@InProceedings{Dolejs2004,
  author    = {Dolejs, O. and Smolik, P. and Hanzalek, Z.},
  booktitle = {{IEEE} {International} {Workshop} on {Factory} {Communication} {Systems}, 2004. {Proceedings}.},
  title     = {On the {Ethernet} use for real-time publish-subscribe based applications},
  year      = {2004},
  month     = sep,
  pages     = {39--44},
  abstract  = {Ethernet is very attractive for the automation area due to its availability and low implementation cost. Due to its media access control (CSMA/CD), Ethernet is not deterministic in general and its behaviour under transient overload is not sufficient for any real-time application. On the other hand, if the applications have predictable and bounded number of requests, behaviour of Ethernet is "nearly" real-time (very low probability of delayed data delivery). This article tests ORTE (open real-time Ethernet), an open-source implementation of RTPS middleware (real-time publish-subscribe), built upon UDP/IP and tested on Ethernet. This middleware can be used in real-time control applications, which typically have limited and relatively small input load compared to the high bandwidth. To derive the influence of the operating system, we combined the application response time measurement with the simulation.},
  doi       = {10.1109/WFCS.2004.1377674},
  file      = {:Dolejs2004 - On the Ethernet Use for Real Time Publish Subscribe Based Applications.pdf:PDF},
  keywords  = {Ethernet networks, Publish-subscribe, Delay, Testing, Middleware, Automation, Costs, Media Access Protocol, Multiaccess communication, Open source software},
}

 
@InProceedings{Jie2013,
  author    = {Jie, Yin and Pei, Ji Yong and Jun, Li and Yun, Guo and Wei, Xu},
  booktitle = {2013 {International} {Conference} on {Computational} and {Information} {Sciences}},
  title     = {Smart {Home} {System} {Based} on {IOT} {Technologies}},
  year      = {2013},
  month     = jun,
  pages     = {1789--1791},
  abstract  = {The idea of applying IOT technologies to smart home system is introduced. An original architecture of the integrated system is analyzed with its detailed introduction. This architecture has great scalability. Based on this proposed architecture many applications can be integrated into the system through uniform interface. Agents are proposed to communicate with appliances through RFID tags. Key issues to be solved to promote the development of smart home system are also discussed.},
  doi       = {10.1109/ICCIS.2013.468},
  file      = {:Jie2013 - Smart Home System Based on IOT Technologies.pdf:PDF},
  keywords  = {Smart homes, Home appliances, Certification, Computer architecture, RFID tags, Internet, Monitoring, smart home, IOT, agent, RFID, architecture},
}

 
@Article{Wortmann2015,
  author   = {Wortmann, Felix and Flüchter, Kristina},
  journal  = {Business \& Information Systems Engineering},
  title    = {Internet of {Things}},
  year     = {2015},
  issn     = {1867-0202},
  month    = jun,
  number   = {3},
  pages    = {221--224},
  volume   = {57},
  doi      = {10.1007/s12599-015-0383-3},
  file     = {:Wortmann2015 - Internet of Things.pdf:PDF},
  keywords = {Internet of things, Technology stack, Platforms},
  language = {en},
  url      = {https://doi.org/10.1007/s12599-015-0383-3},
  urldate  = {2022-10-26},
}

 
@InProceedings{Kampmann2019,
  author    = {Kampmann, Alexandru and Wüstenberg, Andreas and Alrifaee, Bassam and Kowalewski, Stefan},
  booktitle = {2019 {IEEE} {Intelligent} {Transportation} {Systems} {Conference} ({ITSC})},
  title     = {A {Portable} {Implementation} of the {Real}-{Time} {Publish}-{Subscribe} {Protocol} for {Microcontrollers} in {Distributed} {Robotic} {Applications}},
  year      = {2019},
  month     = oct,
  pages     = {443--448},
  abstract  = {This paper presents embeddedRTPS, a portable and open source implementation of the Real-Time Publish-Subscribe Protocol (RTPS). RTPS is the underlying protocol for the Data Distribution Service (DDS), which is a standardized middleware that allows for implementing distributed, loosely-coupled applications. DDS is not only the core protocol for the Robot Operating System (ROS) 2, but is also one of the few protocols that are part of the AUTOSAR Adaptive platform. In contrast to the available open-source RTPS implementations, embeddedRTPS is based on FreeRTOS and lightweightIP and targets resource-constrained embedded platforms. Our contribution allows microcontrollers to become independent, first-class participants in distributed automotive and robotic applications. We benchmark our implementation using a consumer-grade STM32 microprocessor as well as an ASIL-D certified, automotive microcontroller.},
  doi       = {10.1109/ITSC.2019.8916835},
  file      = {:Kampmann2019 - A Portable Implementation of the Real Time Publish Subscribe Protocol for Microcontrollers in Distributed Robotic Applications.pdf:PDF},
  keywords  = {Protocols, Automotive engineering, Message systems, Real-time systems, Microcontrollers, Middleware, Operating systems},
}

 
@TechReport{Mokhtarian2021,
  author   = {Mokhtarian, Armin and Kampmann, Alexandru and Alrifaee, Bassam and Lüer, Maximilian and Kowalewski, Stefan},
  title    = {A {Cloud} {Architecture} for {Networked} and {Autonomous} {Vehicles}},
  year     = {2021},
  number   = {2},
  abstract = {Mokhtarian, Armin; Kampmann, Alexandru; Lüer, Maximilian; Kowalewski, Stefan; Alrifaee, Bassam},
  doi      = {10.1016/j.ifacol.2021.06.028},
  issn     = {2405-8963},
  journal  = {IFAC-PapersOnLine},
  language = {de},
  pages    = {233},
  school   = {Elsevier},
  url      = {https://publications.rwth-aachen.de/record/828696},
  urldate  = {2022-11-02},
  volume   = {54},
}

 
@InProceedings{Kampmann2022,
  author    = {Kampmann, Alexandru and Lüer, Maximilian and Kowalewski, Stefan and Alrifaee, Bassam},
  booktitle = {2022 {IEEE} {Intelligent} {Vehicles} {Symposium} ({IV})},
  title     = {Optimization-based {Resource} {Allocation} for an {Automotive} {Service}-oriented {Software} {Architecture}},
  year      = {2022},
  pages     = {678--687},
  publisher = {IEEE},
}

 
@InProceedings{Kampmann2019a,
  author    = {Kampmann, Alexandru and Alrifaee, Bassam and Kohout, Markus and Wüstenberg, Andreas and Woopen, Timo and Nolte, Marcus and Eckstein, Lutz and Kowalewski, Stefan},
  booktitle = {2019 {IEEE} {Intelligent} {Transportation} {Systems} {Conference} ({ITSC})},
  title     = {A dynamic service-oriented software architecture for highly automated vehicles},
  year      = {2019},
  pages     = {2101--2108},
  publisher = {IEEE},
}

 
@InProceedings{Lewis1996,
  author    = {Lewis, M. and Grimshaw, A.},
  booktitle = {Proceedings of 5th {IEEE} {International} {Symposium} on {High} {Performance} {Distributed} {Computing}},
  title     = {The core {Legion} object model},
  year      = {1996},
  month     = aug,
  note      = {ISSN: 1082-8907},
  pages     = {551--561},
  abstract  = {The Legion project at the University of Virginia is an architecture for designing and building system services that provide the illusion of a single virtual machine to users, a virtual machine that provides secure shared object and shared name spaces, application adjustable fault tolerance, improved response time, and greater throughput. Legion targets wide area assemblies of workstations, supercomputers, and parallel supercomputers. Legion tackles problems not solved by existing workstation based parallel processing tools; the system will enable fault tolerance, wide area parallel processing, interoperability, heterogeneity, a single global name space, protection, security, efficient scheduling, and comprehensive resource management. The paper describes the core Legion object model, which specifies the composition and functionality of Legion's core objects-those objects that cooperate to create, locate, manage, and remove objects in the Legion system. The object model facilitates a flexible extensible implementation, provides a single global name space, grants site autonomy to participating organizations, and scales to millions of sites and trillions of objects.},
  doi       = {10.1109/HPDC.1996.546226},
  file      = {:Lewis1996 - The Core Legion Object Model.pdf:PDF},
  issn      = {1082-8907},
  keywords  = {Virtual machining, Fault tolerant systems, Workstations, Supercomputers, Parallel processing, Buildings, Delay, Throughput, Assembly, Protection},
}

 
@Article{Mahmud2020,
  author     = {Mahmud, Redowan and Ramamohanarao, Kotagiri and Buyya, Rajkumar},
  journal    = {ACM Computing Surveys},
  title      = {Application {Management} in {Fog} {Computing} {Environments}: {A} {Taxonomy}, {Review} and {Future} {Directions}},
  year       = {2020},
  issn       = {0360-0300},
  month      = jul,
  number     = {4},
  pages      = {88:1--88:43},
  volume     = {53},
  abstract   = {The Internet of Things (IoT) paradigm is being rapidly adopted for the creation of smart environments in various domains. The IoT-enabled cyber-physical systems associated with smart city, healthcare, Industry 4.0 and Agtech handle a huge volume of data and require data processing services from different types of applications in real time. The Cloud-centric execution of IoT applications barely meets such requirements as the Cloud datacentres reside at a multi-hop distance from the IoT devices. Fog computing, an extension of Cloud at the edge network, can execute these applications closer to data sources. Thus, Fog computing can improve application service delivery time and resist network congestion. However, the Fog nodes are highly distributed and heterogeneous, and most of them are constrained in resources and spatial sharing. Therefore, efficient management of applications is necessary to fully exploit the capabilities of Fog nodes. In this work, we investigate the existing application management strategies in Fog computing and review them in terms of architecture, placement and maintenance. Additionally, we propose a comprehensive taxonomy and highlight the research gaps in Fog-based application management. We also discuss a perspective model and provide future research directions for further improvement of application management in Fog computing.},
  doi        = {10.1145/3403955},
  file       = {:Mahmud2020 - Application Management in Fog Computing Environments_ a Taxonomy, Review and Future Directions.pdf:PDF},
  keywords   = {application maintenance, application architecture, Fog computing, application placement, Internet of Things},
  shorttitle = {Application {Management} in {Fog} {Computing} {Environments}},
  url        = {https://doi.org/10.1145/3403955},
  urldate    = {2022-12-15},
}

 
@Article{Cheng2018,
  author     = {Cheng, Bin and Solmaz, Gürkan and Cirillo, Flavio and Kovacs, Ernö and Terasawa, Kazuyuki and Kitazawa, Atsushi},
  journal    = {IEEE Internet of Things Journal},
  title      = {{FogFlow}: {Easy} {Programming} of {IoT} {Services} {Over} {Cloud} and {Edges} for {Smart} {Cities}},
  year       = {2018},
  issn       = {2327-4662},
  month      = apr,
  number     = {2},
  pages      = {696--707},
  volume     = {5},
  abstract   = {Smart city infrastructure is forming a large scale Internet of Things (IoT) system with widely deployed IoT devices, such as sensors and actuators that generate a huge volume of data. Given this large scale and geo-distributed nature of such IoT systems, fog computing has been considered as an affordable and sustainable computing paradigm to enable smart city IoT services. However, it is still a major challenge for developers to program their services to leverage benefits of fog computing. Developers have to figure out many details, such as how to dynamically configure and manage data processing tasks over cloud and edges and how to optimize task allocation for minimal latency and bandwidth consumption. In addition, most of the existing fog computing frameworks either lack service programming models or define a programming model only based on their own private data model and interfaces; therefore, as a smart city platform, they are quite limited in terms of openness and interoperability. To tackle these problems, we propose a standard-based approach to design and implement a new fog computing-based framework, namely FogFlow, for IoT smart city platforms. FogFlow’s programming model allows IoT service developers to program elastic IoT services easily over cloud and edges. Moreover, it supports standard interfaces to share and reuse contextual data across services. To showcase how smart city use cases can be realized with FogFlow, we describe three use cases and implement an example application for anomaly detection of energy consumption in smart cities. We also analyze FogFlow’s performance based on microbenchmarking results for message propagation latency, throughput, and scalability.},
  doi        = {10.1109/JIOT.2017.2747214},
  file       = {:Cheng2018 - FogFlow_ Easy Programming of IoT Services Over Cloud and Edges for Smart Cities.pdf:PDF},
  keywords   = {Programming, Smart cities, Computational modeling, Cloud computing, Edge computing, Logic gates, Data models, Internet of Things (IoT), parallel programming},
  shorttitle = {{FogFlow}},
}

 
@Article{Tuli2019,
  author     = {Tuli, Shreshth and Mahmud, Redowan and Tuli, Shikhar and Buyya, Rajkumar},
  journal    = {Journal of Systems and Software},
  title      = {{FogBus}: {A} {Blockchain}-based {Lightweight} {Framework} for {Edge} and {Fog} {Computing}},
  year       = {2019},
  issn       = {0164-1212},
  month      = aug,
  pages      = {22--36},
  volume     = {154},
  abstract   = {Recently much emphasize is given on integrating Edge, Fog and Cloud infrastructures to support the execution of various latency sensitive and computing intensive Internet of Things (IoT) applications. Although different real-world frameworks attempt to assist such integration, they have limitations in respect of platform independence, security, resource management and multi-application execution. To address these limitations, we propose a framework, named FogBus that facilitates end-to-end IoT-Fog(Edge)-Cloud integration. FogBus offers platform independent interfaces to IoT applications and computing instances for execution and interaction. It not only assists developers to build applications but also helps users to run multiple applications at a time and service providers to manage their resources. Moreover, FogBus applies Blockchain, authentication and encryption techniques to secure operations on sensitive data. Due to its simplified and cross platform software systems, it is easy to deploy, scalable and cost efficient. We demonstrate the effectiveness of FogBus by creating a computing environment with it that integrates finger pulse oximeters as IoT devices with Smartphone-based gateway and Raspberry Pi-based Fog nodes for Sleep Apnea analysis. We also evaluate the characteristics of FogBus in respect of other existing frameworks and the impact of various FogBus settings on system parameters through deployment of a real-world IoT application. The experimental results show that FogBus is comparatively lightweight and responsive, and different FogBus settings can tune the computing environment as per the situation demands.},
  doi        = {10.1016/j.jss.2019.04.050},
  file       = {:Tuli2019 - FogBus_ a Blockchain Based Lightweight Framework for Edge and Fog Computing.html:URL},
  keywords   = {Fog computing, Edge computing, Cloud computing, Internet of Things(IoT), Blockchain},
  language   = {en},
  shorttitle = {{FogBus}},
  url        = {https://www.sciencedirect.com/science/article/pii/S0164121219300822},
  urldate    = {2023-01-06},
}

 
@Article{Lakhan2022,
  author   = {Lakhan, Abdullah and Memon, Muhammad Suleman and Mastoi, Qurat-ul-ain and Elhoseny, Mohamed and Mohammed, Mazin Abed and Qabulio, Mumtaz and Abdel-Basset, Mohamed},
  journal  = {Cluster Computing},
  title    = {Cost-efficient mobility offloading and task scheduling for microservices {IoVT} applications in container-based fog cloud network},
  year     = {2022},
  issn     = {1573-7543},
  month    = jun,
  number   = {3},
  pages    = {2061--2083},
  volume   = {25},
  abstract = {These days, the usage of the internet of Vehicle Things (IVoT) applications such as E-Business, E-Train, E-Ambulance has been growing progressively. These applications require mobility-aware delay-sensitive services to execute their tasks. With this motivation, the study has the following contribution. Initially, the study devises a novel cooperative vehicular fog cloud network (VFCN) based on container microservices which offers cost-efficient and mobility-aware services with rich resources for processing. This study devises the cost-efficient task offloading and scheduling (CEMOTS) algorithm framework, which consists of the mobility aware task offloading phase (MTOP) method, which determines the optimal offloading time to minimize the communication cost of applications. Furthermore, CEMOTS offers Cooperative Task Offloading Scheduling (CTOS), including task sequencing and scheduling. The goal is to reduce the application costs of communication cost and computational costs under a given deadline constraint. Performance evaluation shows the CTOS and MTOP outperform existing task offloading and scheduling methods in the VCFN in terms of costs and the deadline for IoT applications.},
  doi      = {10.1007/s10586-021-03333-0},
  file     = {:Lakhan2022 - Cost Efficient Mobility Offloading and Task Scheduling for Microservices IoVT Applications in Container Based Fog Cloud Network.pdf:PDF},
  keywords = {Task offloading, Internet of things, Task scheduling, VFCN, Mobility, Task latency, System costs},
  language = {en},
  url      = {https://doi.org/10.1007/s10586-021-03333-0},
  urldate  = {2023-01-10},
}

 
@Article{Ashraf2022,
  author     = {Ashraf, Maria and Shiraz, Muhammad and Abbasi, Almas and Albahli, Saleh},
  journal    = {Journal of King Saud University - Computer and Information Sciences},
  title      = {Distributed application execution in fog computing: {A} taxonomy, challenges and future directions},
  year       = {2022},
  issn       = {1319-1578},
  month      = jul,
  number     = {7},
  pages      = {3887--3909},
  volume     = {34},
  abstract   = {With tremendous advancements in smart phone industry and IoT devices, edge computing has emerged to provide computational services at edge of the network. As a result, applications can be executed in a distributive manner to meet the latency requirements of applications. Despite these advancements, these devices are still considered to have limited energy, memory and computational resources compared to stationary standalone devices. Mobile edge computing extends mobile cloud computing close to end-users, decreasing latency and bandwidth utilisation by offloading tasks to edge servers. Fog computing places nodes between cloud and edge servers. A challenging approach in these paradigms is establishing offloading decision to edge/fog server, and distributed application execution at run time for heterogeneous devices. This paper reviews execution of resource-intensive tasks on mobile devices in distributed frameworks. The objective is to identify research gaps and highlight new research directions that can be pursued in future. Application execution involves application partitioning, task allocation, task execution and task resumption. In this paper, we propose a separate taxonomy for each step in application execution, reviews state-of-the-art techniques, and analyses critical aspects of application execution in a distributed manner. It further investigates similarities and differences among these techniques based on each step of application execution.},
  doi        = {10.1016/j.jksuci.2022.05.002},
  file       = {:Ashraf2022 - Distributed Application Execution in Fog Computing_ a Taxonomy, Challenges and Future Directions.html:URL},
  keywords   = {Distributed application execution, Fog computing, Mobile edge computing, Application partitioning, Task allocation, Task execution, Task resumption},
  language   = {en},
  shorttitle = {Distributed application execution in fog computing},
  url        = {https://www.sciencedirect.com/science/article/pii/S1319157822001513},
  urldate    = {2023-01-11},
}

 
@Article{Costa2022,
  author     = {Costa, Breno and Bachiega, Joao and de Carvalho, Leonardo Rebouças and Araujo, Aleteia P. F.},
  journal    = {ACM Computing Surveys},
  title      = {Orchestration in {Fog} {Computing}: {A} {Comprehensive} {Survey}},
  year       = {2022},
  issn       = {0360-0300},
  month      = jan,
  number     = {2},
  pages      = {29:1--29:34},
  volume     = {55},
  abstract   = {Fog computing is a paradigm that brings computational resources and services to the network edge in the vicinity of user devices, lowering latency and connecting with cloud computing resources. Unlike cloud computing, fog resources are based on constrained and heterogeneous nodes whose connectivity can be unstable. In this complex scenario, there is a need to define and implement orchestration processes to ensure that applications and services can be provided, considering the settled agreements. Although some publications have dealt with orchestration in fog computing, there are still some diverse definitions and functional intersection with other areas, such as resource management and monitoring. This article presents a systematic review of the literature with focus on orchestration in fog computing. A generic architecture of fog orchestration is presented, created from the consolidation of the analyzed proposals, bringing to light the essential functionalities addressed in the literature. This work also highlights the main challenges and open research questions.},
  doi        = {10.1145/3486221},
  file       = {:Costa2022 - Orchestration in Fog Computing_ a Comprehensive Survey.pdf:PDF},
  keywords   = {resource management, monitoring, Fog computing, orchestration},
  shorttitle = {Orchestration in {Fog} {Computing}},
  url        = {https://doi.org/10.1145/3486221},
  urldate    = {2023-01-13},
}

 
@Article{Mell2011,
  author    = {Mell, Peter M. and Grance, Timothy},
  journal   = {NIST},
  title     = {The {NIST} {Definition} of {Cloud} {Computing}},
  year      = {2011},
  month     = sep,
  abstract  = {Cloud computing is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, s},
  file      = {:Mell2011 - The NIST Definition of Cloud Computing.html:URL},
  language  = {en},
  publisher = {Peter M. Mell, Timothy Grance},
  url       = {https://www.nist.gov/publications/nist-definition-cloud-computing},
  urldate   = {2024-02-16},
}

 
@Book{Benlian2018,
  author     = {Benlian, Alexander and Kettinger, William and Sunyaev, Ali and Winkler, Till},
  title      = {The {Transformative} {Value} of {Cloud} {Computing}: {A} {Decoupling}, {Platformization}, and {Recombination} {Theoretical} {Framework}},
  year       = {2018},
  month      = may,
  abstract   = {To guide future research in cloud computing, this JMIS Special Section Introduction presents a framework for research, the Transformative Impact of Cloud Computing (TICC) framework. The TICC framework delineates IT value from transformative value and describes three key mechanisms through which cloud computing capabilities, individually and in combination, generate transformative impacts (hereafter referred to as transformative mechanisms): (1) decoupling, (2) platformization, and (3) recombination of services. We first evaluate how the transformative mechanisms arise from each of the technical layers of cloud computing (i.e., infrastructure resources, components, and applications). Then, we analyze and extrapolate how each of the transformative mechanisms leads to impacts on individuals, organizations, and societies/economies (i.e., hereafter also referred to as the real-world layers). We close by presenting an agenda for future research and mapping the three papers included in this Special Section to the TICC framework.},
  file       = {Full Text PDF:https\://www.researchgate.net/profile/Alexander-Benlian/publication/324968806_The_Transformative_Value_of_Cloud_Computing_A_Decoupling_Platformization_and_Recombination_Theoretical_Framework/links/5aeda109458515f59982fa06/The-Transformative-Value-of-Cloud-Computing-A-Decoupling-Platformization-and-Recombination-Theoretical-Framework.pdf:application/pdf;ResearchGate Link:https\://www.researchgate.net/publication/324968806_The_Transformative_Value_of_Cloud_Computing_A_Decoupling_Platformization_and_Recombination_Theoretical_Framework:},
  shorttitle = {The {Transformative} {Value} of {Cloud} {Computing}},
}

 
@Article{Marston2011,
  author   = {Marston, Sean and Li, Zhi and Bandyopadhyay, Subhajyoti and Zhang, Juheng and Ghalsasi, Anand},
  journal  = {Decision Support Systems},
  title    = {Cloud computing — {The} business perspective},
  year     = {2011},
  issn     = {0167-9236},
  month    = apr,
  number   = {1},
  pages    = {176--189},
  volume   = {51},
  abstract = {The evolution of cloud computing over the past few years is potentially one of the major advances in the history of computing. However, if cloud computing is to achieve its potential, there needs to be a clear understanding of the various issues involved, both from the perspectives of the providers and the consumers of the technology. While a lot of research is currently taking place in the technology itself, there is an equally urgent need for understanding the business-related issues surrounding cloud computing. In this article, we identify the strengths, weaknesses, opportunities and threats for the cloud computing industry. We then identify the various issues that will affect the different stakeholders of cloud computing. We also issue a set of recommendations for the practitioners who will provide and manage this technology. For IS researchers, we outline the different areas of research that need attention so that we are in a position to advice the industry in the years to come. Finally, we outline some of the key issues facing governmental agencies who, due to the unique nature of the technology, will have to become intimately involved in the regulation of cloud computing.},
  doi      = {10.1016/j.dss.2010.12.006},
  file     = {ScienceDirect Full Text PDF:https\://www.sciencedirect.com/science/article/pii/S0167923610002393/pdfft?md5=835bb861541e9a39e05eb6feffa79fdf&pid=1-s2.0-S0167923610002393-main.pdf&isDTMRedir=Y:application/pdf},
  keywords = {Cloud computing, Virtualization, Software as a service, Platform as a service, Infrastructure as a service, On-demand computing, Cloud computing regulation},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167923610002393},
  urldate  = {2024-02-28},
}

 
@InCollection{Arasaratnam2011,
  author    = {Arasaratnam, Omkhar},
  booktitle = {Auditing {Cloud} {Computing}},
  publisher = {John Wiley \& Sons, Ltd},
  title     = {Introduction to {Cloud} {Computing}},
  year      = {2011},
  chapter   = {1},
  isbn      = {9781118269091},
  pages     = {1--13},
  abstract  = {This chapter contains sections titled: History Defining Cloud Computing Cloud Computing Services Layers Roles in Cloud Computing Cloud Computing Deployment Models Challenges In Summary},
  copyright = {Copyright © 2011 Ben Halpert. All rights reserved.},
  doi       = {10.1002/9781118269091.ch1},
  file      = {Full Text PDF:https\://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/9781118269091.ch1:application/pdf},
  keywords  = {high performance computing, cloud computing, departmental computers, world wide web, Google},
  language  = {en},
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118269091.ch1},
  urldate   = {2024-02-29},
}

 
@Book{Marinescu2022,
  author     = {Marinescu, Dan C.},
  publisher  = {Morgan Kaufmann},
  title      = {Cloud {Computing}: {Theory} and {Practice}},
  year       = {2022},
  isbn       = {9780323910477},
  month      = feb,
  note       = {Google-Books-ID: XOBWEAAAQBAJ},
  abstract   = {Cloud Computing: Theory and Practice, Third Edition provides students and IT professionals with an in-depth analysis of the cloud from the ground up. After an introduction to network-centric computing and network-centric content, the book reviews basic concepts of concurrency and parallel and distributed systems, presents critical components of the cloud ecosystem as cloud service providers, cloud access, cloud data storage, and cloud hardware and software, covers cloud applications and cloud security, and presents research topics in cloud computing. Specific topics covered include resource virtualization, resource management and scheduling, and advanced topics like the impact of scale on efficiency, cloud scheduling subject to deadlines, alternative cloud architectures, and vehicular clouds. An included glossary covers terms grouped in several categories, from general to services, virtualization, desirable attributes and security. Presents updated content throughout chapters on concurrency, cloud hardware and software, challenges posed by big data, mobile applications and advanced topics Includes an expanded appendix that presents several cloud computing projects Provides more than 400 references in the text, including recent research results in several areas related to cloud computing},
  file       = {:Marinescu2022 - Cloud Computing_ Theory and Practice.html:URL},
  keywords   = {Computers / Distributed Systems / General, Computers / Internet / General, Computers / Networking / General, Mathematics / Discrete Mathematics, Computers / Computer Architecture, Computers / Information Theory, Computers / General, Computers / Programming / Parallel, Computers / Web / General, Language Arts \& Disciplines / Library \& Information Science / General},
  language   = {en},
  shorttitle = {Cloud {Computing}},
}

 
@Misc{Stat2024,
  month      = feb,
  title      = {Infographic: {Amazon} {Maintains} {Cloud} {Lead} as {Microsoft} {Edges} {Closer}},
  year       = {2024},
  abstract   = {This chart shows worldwide market share of leading cloud infrastructure service providers in Q4 2023.},
  journal    = {Statista Daily Data},
  language   = {en},
  shorttitle = {Infographic},
  url        = {https://www.statista.com/chart/18819/worldwide-market-share-of-leading-cloud-infrastructure-service-providers},
  urldate    = {2024-03-05},
}

 
@Misc{AWS2023,
  author       = {AWS23},
  howpublished = {Website},
  title        = {Was ist verteiltes {Computing}? - {Verteiltes} {Computing} erklärt - {AWS}},
  year         = {2023},
  abstract     = {Was ist verteiltes Computing, wie und warum Unternehmen verteiltes Computing verwenden und wie verteiltes Computing mit AWS verwendet wird.},
  journal      = {Amazon Web Services, Inc.},
  language     = {de-DE},
  shorttitle   = {Was ist verteiltes {Computing}?},
  url          = {https://aws.amazon.com/de/what-is/distributed-computing/},
  urldate      = {2024-03-06},
}

 
@book{arpaci2018operating,
  title={Operating systems: Three easy pieces},
  author={Arpaci-Dusseau, Remzi H and Arpaci-Dusseau, Andrea C},
  year={2018},
  publisher={Arpaci-Dusseau Books, LLC}
}

@article{ord1994scale,
  title={Scale in distributed systems},
  author={ord Neuman, B Cli},
  journal={ISI/USC},
  pages={68},
  year={1994}
}

 
@Article{Lin2020,
  author   = {Lin, Hai and Zeadally, Sherali and Chen, Zhihong and Labiod, Houda and Wang, Lusheng},
  journal  = {Journal of Network and Computer Applications},
  title    = {A survey on computation offloading modeling for edge computing},
  year     = {2020},
  issn     = {1084-8045},
  month    = nov,
  pages    = {102781},
  volume   = {169},
  abstract = {As a promising technology, edge computing extends computation, communication, and storage facilities toward the edge of a network. This new computing paradigm opens up new challenges, among which computation offloading is considered to be the most important one. Computation offloading enables end devices to offload computation tasks to edge servers and receive the results after the servers' execution of the tasks. In computation offloading, offloading modeling plays a crucial role in determining the overall edge computing performance. We present a comprehensive overview on the past development as well as the recent advances in research areas related to offloading modeling in edge computing. First, we present some important edge computing architectures and classify the previous works on computation offloading into different categories. Second, we discuss some basic models such as channel model, computation and communication model, and energy harvesting model that have been proposed in offloading modeling. Next, we elaborate on different offloading modeling methods which are based on (non-)convex optimization, Markov decision process, game theory, Lyapunov optimization, or machine learning. Finally, we highlight and discuss some research directions and challenges in the area of offloading modeling in edge computing.},
  doi      = {10.1016/j.jnca.2020.102781},
  file     = {ScienceDirect Full Text PDF:https\://www.sciencedirect.com/science/article/pii/S1084804520302551/pdfft?md5=a4116dae0966366613c1b075002dbc9f&pid=1-s2.0-S1084804520302551-main.pdf&isDTMRedir=Y:application/pdf},
  keywords = {Computation offloading, Edge computing, Modeling},
  url      = {https://www.sciencedirect.com/science/article/pii/S1084804520302551},
  urldate  = {2024-03-14},
}

 
@Article{Wang2019,
  author   = {Wang, Shangguang and Zhao, Yali and Xu, Jinlinag and Yuan, Jie and Hsu, Ching-Hsien},
  journal  = {Journal of Parallel and Distributed Computing},
  title    = {Edge server placement in mobile edge computing},
  year     = {2019},
  issn     = {0743-7315},
  month    = may,
  pages    = {160--168},
  volume   = {127},
  abstract = {With the rapid increase in the development of the Internet of Things and 5G networks in the smart city context, a large amount of data (i.e., big data) is expected to be generated, resulting in increased latency for the traditional cloud computing paradigm. To reduce the latency, mobile edge computing has been considered for offloading a part of the workload from mobile devices to nearby edge servers that have sufficient computation resources. Although there has been significant research in the field of mobile edge computing, little attention has been given to understanding the placement of edge servers in smart cities to optimize the mobile edge computing network performance. In this paper, we study the edge server placement problem in mobile edge computing environments for smart cities. First, we formulate the problem as a multi-objective constraint optimization problem that places edge servers in some strategic locations with the objective to make balance the workloads of edge servers and minimize the access delay between the mobile user and edge server. Then, we adopt mixed integer programming to find the optimal solution. Experimental results based on Shanghai Telecom’s base station dataset show that our approach outperforms several representative approaches in terms of access delay and workload balancing.},
  doi      = {10.1016/j.jpdc.2018.06.008},
  file     = {ScienceDirect Full Text PDF:https\://www.sciencedirect.com/science/article/pii/S0743731518304398/pdfft?md5=442e2bcb1e7d97f5c01086da5f5f994f&pid=1-s2.0-S0743731518304398-main.pdf&isDTMRedir=Y:application/pdf},
  keywords = {Mobile edge computing, Smart city edge server placement, Workload balancing, Access delay},
  url      = {https://www.sciencedirect.com/science/article/pii/S0743731518304398},
  urldate  = {2024-03-15},
}

 
@InProceedings{Varsha2017,
  author    = {Varsha, H. S. and Shashikala, K. P.},
  booktitle = {2017 {International} {Conference} on {Innovative} {Mechanisms} for {Industry} {Applications} ({ICIMIA})},
  title     = {The tactile {Internet}},
  year      = {2017},
  month     = feb,
  pages     = {419--422},
  abstract  = {The notion of the Tactile Internet is burgeoning which permits us to transmit actuation and touch in real-time. With technological advancement, communication comprising of both voice and data which is pushing forward the structure of the current network, haptic communications will be enabled by tactile internet, which in turn will be a fundamental change to the way the global skill sets would be delivered. The tactile internet is at the grass root level meaning that the research and development related to this particular field is still in progress. The aim is to delve deeper into some of the challenges faced and propose. solutions which would result in the breakthrough of tactile internet.},
  doi       = {10.1109/ICIMIA.2017.7975649},
  file      = {:Varsha2017 - The Tactile Internet.html:URL},
  keywords  = {Internet, Exoskeletons, Delays, Haptic interfaces, Reliability, Servers, Medical services, haptic communication, latency, reliability, tactile internet},
  url       = {https://ieeexplore.ieee.org/abstract/document/7975649},
  urldate   = {2024-03-18},
}

 
@Article{Pahl2015,
  author   = {Pahl, Claus},
  journal  = {IEEE Cloud Computing},
  title    = {Containerization and the {PaaS} {Cloud}},
  year     = {2015},
  issn     = {2325-6095},
  month    = may,
  number   = {3},
  pages    = {24--31},
  volume   = {2},
  abstract = {Containerization is widely discussed as a lightweight virtualization solution. Apart from exhibiting benefits over traditional virtual machines in the cloud, containers are especially relevant for platform-as-a-service (PaaS) clouds to manage and orchestrate applications through containers as an application packaging mechanism. This article discusses the requirements that arise from having to facilitate applications through distributed multicloud platforms.},
  doi      = {10.1109/MCC.2015.51},
  file     = {:Pahl2015 - Containerization and the PaaS Cloud.html:URL},
  keywords = {Containerization, Virtualization, File systems, Linux, Computer architecture, Packaging, cloud, cloud computing, cluster, container, Docker, Kubernetes, multicloud, PaaS, virtualization},
  url      = {https://ieeexplore.ieee.org/document/7158965},
  urldate  = {2024-03-25},
}

 
@Article{Bugnion2012,
  author   = {Bugnion, Edouard and Devine, Scott and Rosenblum, Mendel and Sugerman, Jeremy and Wang, Edward Y.},
  journal  = {ACM Transactions on Computer Systems},
  title    = {Bringing {Virtualization} to the x86 {Architecture} with the {Original} {VMware} {Workstation}},
  year     = {2012},
  issn     = {0734-2071},
  month    = nov,
  number   = {4},
  pages    = {12:1--12:51},
  volume   = {30},
  abstract = {This article describes the historical context, technical challenges, and main implementation techniques used by VMware Workstation to bring virtualization to the x86 architecture in 1999. Although virtual machine monitors (VMMs) had been around for decades, they were traditionally designed as part of monolithic, single-vendor architectures with explicit support for virtualization. In contrast, the x86 architecture lacked virtualization support, and the industry around it had disaggregated into an ecosystem, with different vendors controlling the computers, CPUs, peripherals, operating systems, and applications, none of them asking for virtualization. We chose to build our solution independently of these vendors. As a result, VMware Workstation had to deal with new challenges associated with (i) the lack of virtualization support in the x86 architecture, (ii) the daunting complexity of the architecture itself, (iii) the need to support a broad combination of peripherals, and (iv) the need to offer a simple user experience within existing environments. These new challenges led us to a novel combination of well-known virtualization techniques, techniques from other domains, and new techniques. VMware Workstation combined a hosted architecture with a VMM. The hosted architecture enabled a simple user experience and offered broad hardware compatibility. Rather than exposing I/O diversity to the virtual machines, VMware Workstation also relied on software emulation of I/O devices. The VMM combined a trap-and-emulate direct execution engine with a system-level dynamic binary translator to efficiently virtualize the x86 architecture and support most commodity operating systems. By relying on x86 hardware segmentation as a protection mechanism, the binary translator could execute translated code at near hardware speeds. The binary translator also relied on partial evaluation and adaptive retranslation to reduce the overall overheads of virtualization. Written with the benefit of hindsight, this article shares the key lessons we learned from building the original system and from its later evolution.},
  doi      = {10.1145/2382553.2382554},
  file     = {:Bugnion2012 - Bringing Virtualization to the X86 Architecture with the Original VMware Workstation.pdf:PDF},
  keywords = {VMM, Virtualization, dynamic binary translation, hypervisors, virtual machine monitors, x86},
  url      = {https://dl.acm.org/doi/10.1145/2382553.2382554},
  urldate  = {2024-03-27},
}

 
@Article{Bhardwaj2021,
  author     = {Bhardwaj, Aditya and Krishna, C. Rama},
  journal    = {Arabian Journal for Science and Engineering},
  title      = {Virtualization in {Cloud} {Computing}: {Moving} from {Hypervisor} to {Containerization}—{A} {Survey}},
  year       = {2021},
  issn       = {2191-4281},
  month      = sep,
  number     = {9},
  pages      = {8585--8601},
  volume     = {46},
  abstract   = {Containers emerged as a lightweight alternative to virtual machines that offer better microservice architecture support. They are widely used by organizations to deploy their increasingly diverse workloads derived from modern applications such as big data, IoT, and edge/fog computing in either proprietary clusters or private, public cloud data centers. With the growing interest in container-based virtualization technologies, the requirement to explore the deployment and orchestration of clusters of containers has become a central research problem. Although progress has been made to study containerization, systematic consolidation of the existing literature with a summative evaluation is still missing. To fill this gap, in this paper, we first taxonomically classify the existing research studies on the performance comparison between hypervisor and container technology and then analyze state-of-the-art for container cluster management orchestration systems, its performance monitoring tools, and finally future research trends. This results in a better understanding of container technology with attention to provide summative analysis in terms of (i) how much performance overhead is generated by a hypervisor compared to container-based virtualization, (ii) which container technology is suited for a cloud application deployment based on the type of benchmark executing, (iii) how to provide management of containers deployed in a cluster environment, (iv) container performance monitoring tools, and (v) finally emerging concerns for future research directions.},
  doi        = {10.1007/s13369-021-05553-3},
  file       = {:Bhardwaj2021 - Virtualization in Cloud Computing_ Moving from Hypervisor to Containerization—A Survey.pdf:PDF},
  keywords   = {Cloud computing, Virtualization, Hypervisor, Containerization},
  language   = {en},
  shorttitle = {Virtualization in {Cloud} {Computing}},
  url        = {https://doi.org/10.1007/s13369-021-05553-3},
  urldate    = {2024-03-27},
}

 
@Article{Mavridis2019,
  author   = {Mavridis, Ilias and Karatza, Helen},
  journal  = {Future Generation Computer Systems},
  title    = {Combining containers and virtual machines to enhance isolation and extend functionality on cloud computing},
  year     = {2019},
  issn     = {0167-739X},
  month    = may,
  pages    = {674--696},
  volume   = {94},
  abstract = {Virtualization technology is the underlying element of cloud computing. Traditionally, cloud computing has employed virtual machines to distribute available resources and provide isolated environments among users. Multiple virtual machines, with their own operating system and services, can be deployed and run simultaneously on the same physical machine on the cloud infrastructure. Recently, a more lightweight virtualization technology is being rapidly adopted and it is based on containers. A key difference between virtual machines and containers, is that containers share the same underlying operating system. In this work, we studied the combination of these two virtualization technologies by running containers on top of virtual machines. This synergy aims to enhance containers’ main drawback, which is isolation and, among others, to simplify the system management and upgrade, and to introduce the new functionalities of containerized applications to virtual machines. The benefits of this method have been recognized by big cloud companies, which have been employing this approach for years. With this paper, we aimed to present the advantages of running containers on virtual machines and to explore how various virtualization techniques and configurations affect the performance of this method. Although, in bibliography there are a few papers that used this method partially to conduct experiments, there is not any research which considers this method from our integral aspect of view. In this study, we ran Docker containers and evaluated their performances, not only on KVM and XEN virtual machines, but also we ran Linux containers on Windows Server. We adopted an empirical approach, to quantify the performance overhead introduced by the additional virtualization layer of virtual machines, by executing various benchmarks and deploying real world applications as use cases. Furthermore, we presented for first time, how isolation is applied on virtual machines and containers, we evaluated different operating systems optimized to host containers, mechanisms of storing persistent data and, last but not least, we experimentally quantified the power and energy consumption overhead of containers running on virtual machines.},
  doi      = {10.1016/j.future.2018.12.035},
  file     = {ScienceDirect Full Text PDF:https\://www.sciencedirect.com/science/article/pii/S0167739X18305764/pdfft?md5=01e5d2e537b6ce4ca0b8ace916621880&pid=1-s2.0-S0167739X18305764-main.pdf&isDTMRedir=Y:application/pdf},
  keywords = {Docker, VMs, Containers, KVM, XEN, Hyper-V, Performance evaluation, Energy consumption},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167739X18305764},
  urldate  = {2024-04-03},
}

 
@Article{Martin2018,
  author   = {Martin, John Paul and Kandasamy, A. and Chandrasekaran, K.},
  journal  = {Human-centric Computing and Information Sciences},
  title    = {Exploring the support for high performance applications in the container runtime environment},
  year     = {2018},
  issn     = {2192-1962},
  month    = jan,
  number   = {1},
  pages    = {1},
  volume   = {8},
  abstract = {Cloud computing is the driving power behind the current technological era. Virtualization is rightly referred to as the backbone of cloud computing. Impacts of virtualization employed in high performance computing (HPC) has been much reviewed by researchers. The overhead in the virtualization layer was one of the reasons which hindered its application in the HPC environment. Recent developments in virtualization, especially the OS container based virtualization provides a solution that employs a lightweight virtualization layer and promises lesser overhead. Containers are advantageous over virtual machines in terms of performance overhead which is a major concern in the case of both data intensive applications and compute intensive applications. Currently, several industries have adopted container technologies such as Docker. While Docker is widely used, it has certain pitfalls such as security issues. The recently introduced CoreOS Rkt container technology overcomes these shortcomings of Docker. There has not been much research on how the Rkt environment is suited for high performance applications. The differences in the stack of the Rkt containers suggest better support for high performance applications. High performance applications consist of CPU-intensive and data-intensive applications. The High Performance Linpack Library and the Graph500 are the commonly used computation intensive and data-intensive benchmark applications respectively. In this work, we explore the feasibility of this inter-operable Rkt container in high performance applications by running the HPL and Graph500 applications and compare its performance with the commonly used container technologies such as LXC and Docker containers.},
  doi      = {10.1186/s13673-017-0124-3},
  file     = {:Martin2018 - Exploring the Support for High Performance Applications in the Container Runtime Environment.pdf:PDF},
  keywords = {Cloud computing, Containers, High performance computing, Core OS Rkt, Docker, LXC, Linpack, Graph 500},
  language = {en},
  url      = {https://doi.org/10.1186/s13673-017-0124-3},
  urldate  = {2024-04-03},
}

 
@Article{Dall2014,
  author     = {Dall, Christoffer and Nieh, Jason},
  journal    = {ACM SIGPLAN Notices},
  title      = {{KVM}/{ARM}: the design and implementation of the linux {ARM} hypervisor},
  year       = {2014},
  issn       = {0362-1340},
  month      = feb,
  number     = {4},
  pages      = {333--348},
  volume     = {49},
  abstract   = {As ARM CPUs become increasingly common in mobile devices and servers, there is a growing demand for providing the benefits of virtualization for ARM-based devices. We present our experiences building the Linux ARM hypervisor, KVM/ARM, the first full system ARM virtualization solution that can run unmodified guest operating systems on ARM multicore hardware. KVM/ARM introduces split-mode virtualization, allowing a hypervisor to split its execution across CPU modes and be integrated into the Linux kernel. This allows KVM/ARM to leverage existing Linux hardware support and functionality to simplify hypervisor development and maintainability while utilizing recent ARM hardware virtualization extensions to run virtual machines with comparable performance to native execution. KVM/ARM has been successfully merged into the mainline Linux kernel, ensuring that it will gain wide adoption as the virtualization platform of choice for ARM. We provide the first measurements on real hardware of a complete hypervisor using ARM hardware virtualization support. Our results demonstrate that KVM/ARM has modest virtualization performance and power costs, and can achieve lower performance and power costs compared to x86-based Linux virtualization on multicore hardware.},
  doi        = {10.1145/2644865.2541946},
  file       = {:Dall2014 - KVM_ARM_ the Design and Implementation of the Linux ARM Hypervisor.pdf:PDF},
  keywords   = {arm, hypervisors, linux, multicore, operating systems, virtualization},
  shorttitle = {{KVM}/{ARM}},
  url        = {https://dl.acm.org/doi/10.1145/2644865.2541946},
  urldate    = {2024-04-05},
}

 
@Misc{Red_2024,
  author   = {RedHat},
  month    = apr,
  title    = {Chapter 1. {Introduction} to {Linux} {Containers} {Red} {Hat} {Enterprise} {Linux} {Atomic} {Host} 7 {\textbar} {Red} {Hat} {Customer} {Portal}},
  year     = {2024},
  language = {en},
  url      = {https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_atomic_host/7/html/overview_of_containers_in_red_hat_systems/introduction_to_linux_containers},
  urldate  = {2024-04-10},
}

 
@Misc{sen2024,
  author   = {6sense},
  month    = apr,
  title    = {Best {Cloud} {Operations} {Management} {Software} in 2024},
  year     = {2024},
  abstract = {Find and compare different software \& technologies in the Cloud Operations Management industry.},
  journal  = {6sense},
  url      = {https://www.6sense.com/tech/cloud-operations-management},
  urldate  = {2024-04-18},
}

 
@Article{Shukur2020,
  author    = {Shukur, Hanan and Zeebaree, Subhi and Zebari, Rizgar and Zeebaree, Diyar and Ahmed, Omar and Salih, Azar},
  journal   = {Journal of Applied Science and Technology Trends},
  title     = {Cloud {Computing} {Virtualization} of {Resources} {Allocation} for {Distributed} {Systems}},
  year      = {2020},
  issn      = {2708-0757},
  month     = jun,
  number    = {2},
  pages     = {98--105},
  volume    = {1},
  abstract  = {Cloud computing is a new technology which managed by a third party “cloud provider” to provide the clients with services anywhere, at any time, and under various circumstances. In order to provide clients with cloud resources and satisfy their needs, cloud computing employs virtualization and resource provisioning techniques.  The process of providing clients with shared virtualized resources (hardware, software, and platform) is a big challenge for the cloud provider because of over-provision and under-provision problems. Therefore, this paper highlighted some proposed approaches and scheduling algorithms applied for resource allocation within cloud computing through virtualization in the datacenter. The paper also aims to explore the role of virtualization in providing resources effectively based on clients’ requirements. The results of these approaches showed that each proposed approach and scheduling algorithm has an obvious role in utilizing the shared resources of the cloud data center. The paper also explored that virtualization technique has a significant impact on enhancing the network performance, save the cost by reducing the number of Physical Machines (PM) in the datacenter, balance the load, conserve the server’s energy, and allocate resources actively thus satisfying the clients’ requirements. Based on our review, the availability of Virtual Machine (VM) resource and execution time of requests are the key factors to be considered in any optimal resource allocation algorithm. As a results of our analyzing for the proposed approaches is that the requests execution time and VM availability are main issues and should in consideration in any allocating resource approach.},
  copyright = {Copyright (c) 2020 Hanan M. Shukur, Subhi R. M. Zeebaree, Rizgar R. Zebari, Diyar Qader Zeebaree, Omar M. Ahmed, Azar Abid Salih},
  doi       = {10.38094/jastt1331},
  file      = {:Shukur2020 - Cloud Computing Virtualization of Resources Allocation for Distributed Systems.pdf:PDF},
  keywords  = {Distributed Systems},
  language  = {en},
  url       = {https://www.jastt.org/index.php/jasttpath/article/view/31},
  urldate   = {2024-04-24},
}

 
@Misc{Red2_2024,
  author       = {RedHat},
  howpublished = {Website},
  month        = may,
  title        = {Chapter 1. {Components} {Red} {Hat} {OpenStack} {Platform} 11 {\textbar} {Red} {Hat} {Customer} {Portal}},
  year         = {2024},
  language     = {en},
  url          = {https://access.redhat.com/documentation/de-de/red_hat_openstack_platform/11/html/architecture_guide/components},
  urldate      = {2024-05-03},
}

@Article{Foundation2024,
  author = {OpenStack Foundation},
  title  = {Nova Documentation},
  year   = {2024},
  file   = {:-.pdf:PDF},
}

 
@InProceedings{Nayak2023,
  author     = {Nayak, Naresh and Grewe, Dennis and Schildt, Sebastian},
  booktitle  = {2023 {IEEE} {Vehicular} {Networking} {Conference} ({VNC})},
  title      = {Automotive {Container} {Orchestration}: {Requirements}, {Challenges} and {Open} {Directions}},
  year       = {2023},
  month      = apr,
  note       = {ISSN: 2157-9865},
  pages      = {61--64},
  abstract   = {After having changed the landscape of software development and operations in cloud computing, virtualization technologies such as containers have now become a technology of interest for in-vehicular E/E architectures. Packaging software components and all their dependencies into portable containers is promising to simplify the deployments on modern in-vehicle platforms. A key component to distribute and manage containerized applications within a computing system is the orchestrator. As a logically centralized component, it is responsible to deploy, manage and monitor containerized applications and their health state and migrate them if necessary, e.g., in event of failures. However, the design of the existing orchestration solutions, such as Kubernetes (k8s), is mainly driven by cloud or IoT applications, not addressing the requirements of automotive applications such as heterogeneous communication networks or functional safety. In this paper, we discuss the functions of an automotive grade container orchestrator in an in-vehicular network and elicit its requirements. We explore k3s, a specialized orchestration framework for edge computing, and highlight its shortcomings for usage in automotive networks. Finally, we conclude with a set of open challenges and directions towards the development of an automotive grade container orchestrator.},
  doi        = {10.1109/VNC57357.2023.10136278},
  file       = {:Nayak2023 - Automotive Container Orchestration_ Requirements, Challenges and Open Directions.html:URL},
  issn       = {2157-9865},
  keywords   = {Cloud computing, Computer architecture, Containers, Packaging, Market research, Software, Safety, Containerization, Orchestration, Safety, Requirements Engineering},
  shorttitle = {Automotive {Container} {Orchestration}},
  url        = {https://ieeexplore.ieee.org/document/10136278},
  urldate    = {2024-06-03},
}

 
@Article{Sinha2021,
  author   = {Sinha, Soham and West, Richard},
  journal  = {ACM Transactions on Embedded Computing Systems},
  title    = {Towards an {Integrated} {Vehicle} {Management} {System} in {DriveOS}},
  year     = {2021},
  issn     = {1539-9087},
  month    = sep,
  number   = {5s},
  pages    = {82:1--82:24},
  volume   = {20},
  abstract = {Modern automotive systems feature dozens of electronic control units (ECUs) for chassis, body and powertrain functions. These systems are costly and inflexible to upgrade, requiring ever increasing numbers of ECUs to support new features such as advanced driver assistance (ADAS), autonomous technologies, and infotainment. To counter these challenges, we propose DriveOS, a safe, secure, extensible, and timing-predictable system for modern vehicle management in a centralized platform. DriveOS is based on a separation kernel, where timing and safety-critical ECU functions are implemented in a real-time OS (RTOS) alongside non-critical software in Linux or Android. The system enforces the separation, or partitioning, of both software and hardware among different OSes. DriveOS runs on a relatively low-cost embedded PC-class platform, supporting multiple cores and hardware virtualization capabilities. Instrument cluster, in-vehicle infotainment and advanced driver assistance system services are implemented in a Yocto Linux guest, which communicates with critical real-time services via secure shared memory. The RTOS manages a real-time controller area network (CAN) interface that is inaccessible to Linux services except via well-defined and legitimate communication channels. In this work, we integrate three Qt-based services written for Yocto Linux, running in parallel with a real-time longitudinal controller task and multiple CAN bus concentrators, for vehicular sensor data processing and actuation. We demonstrate the benefits and performance of DriveOS with a hardware-in-the-loop CARLA simulation using a real car dataset.},
  doi      = {10.1145/3477013},
  file     = {:Sinha2021 - Towards an Integrated Vehicle Management System in DriveOS.pdf:PDF},
  keywords = {Automotive systems, safety-criticality, partitioning hypervisor},
  url      = {https://dl.acm.org/doi/10.1145/3477013},
  urldate  = {2024-06-05},
}

 
@Article{Talpes2020,
  author   = {Talpes, Emil and Sarma, Debjit Das and Venkataramanan, Ganesh and Bannon, Peter and McGee, Bill and Floering, Benjamin and Jalote, Ankit and Hsiong, Christopher and Arora, Sahil and Gorti, Atchyuth and Sachdev, Gagandeep S.},
  journal  = {IEEE Micro},
  title    = {Compute {Solution} for {Tesla}'s {Full} {Self}-{Driving} {Computer}},
  year     = {2020},
  issn     = {1937-4143},
  month    = mar,
  number   = {2},
  pages    = {25--35},
  volume   = {40},
  abstract = {Tesla's full self-driving (FSD) computer is the world's first purpose-built computer for the highly demanding workloads of autonomous driving. It is based on a new System on a Chip (SoC) that integrates industry standard components such as CPUs, ISP, and GPU, together with our custom neural network accelerators. The FSD computer is capable of processing up to 2300 frames per second, a 21× improvement over Tesla's previous hardware and at a lower cost, and when fully utilized, enables a new level of safety and autonomy on the road.},
  doi      = {10.1109/MM.2020.2975764},
  file     = {:Talpes2020 - Compute Solution for Tesla's Full Self Driving Computer.html:URL},
  keywords = {Convolution, Autonomous systems, Artificial neural networks, Random access memory, Graphics processing units},
  url      = {https://ieeexplore.ieee.org/document/9007413},
  urldate  = {2024-06-05},
}

 
@Book{Reinhardt2013,
  author = {Reinhardt, Dominik and Kucera, Markus},
  title  = {Domain {Controlled} {Architecture} - {A} {New} {Approach} for {Large} {Scale} {Software} {Integrated} {Automotive} {Systems}},
  year   = {2013},
  month  = jan,
  file   = {ResearchGate Link:https\://www.researchgate.net/publication/259623365_Domain_Controlled_Architecture_-_A_New_Approach_for_Large_Scale_Software_Integrated_Automotive_Systems:},
  pages  = {226},
}

 
@Article{DiNatale2010,
  author     = {Di Natale, Marco and Sangiovanni-Vincentelli, Alberto Luigi},
  journal    = {Proceedings of the IEEE},
  title      = {Moving {From} {Federated} to {Integrated} {Architectures} in {Automotive}: {The} {Role} of {Standards}, {Methods} and {Tools}},
  year       = {2010},
  issn       = {1558-2256},
  month      = apr,
  number     = {4},
  pages      = {603--620},
  volume     = {98},
  abstract   = {Cost pressure, flexibility, extensibility and the need for coping with increased functional complexity are changing the fundamental paradigms for the definition of automotive and aeronautics architectures. Traditional designs are based on the concept of a Federated Architecture in which integrated hardware/software components [Electronic Control Units (ECUs)] realize mostly independent or loosely interconnected functions. These components are connected by bus and cooperate by exchanging messages. This paradigm is now being replaced by the Integrated Architecture,—the concept comes from Integrated Modular Avionics (IMA) introduced by the avionics community (see C. B. Watkins and R. Walter, “Transitioning from federated avionics architectures to integrated modular avionics,” in Proc. 26th Digital Avionics Syst. Conf., Oct. 2007) but it is certainly general and applicable to other fields and in particular, automotive—in which software components can be supplied from multiple sources, integrated on the same hardware platform or physically distributed and possibly moved from one CPU to another without loss of functional and time correctness and providing a guaranteed level of reliability. This shift will decouple software design from the hardware platform design and provide opportunities for the optimization of the architecture configuration, increased extensibility, flexibility and modularity. However, the integration of software components in a distributed system realizing a complex functional behavior and characterized by safety, time and reliability constraints requires a much tighter control on the component model and its semantics, new methods and tools for analyzing the results of the composition, whether by simulation or formal methods, and methods for exploring the architecture solution space and optimizing the configuration. We provide a general overview of existing challenges and possible solutions to the design and analysis problem, with special focus on the automotive domain. The development of such methods and tools must necessarily consider compatibility with existing modeling languages and standards, including UML, AUTOSAR and synchronous reactive models, on which the widely used commercial products Simulink and SCADE are based.},
  doi        = {10.1109/JPROC.2009.2039550},
  file       = {:DiNatale2010 - Moving from Federated to Integrated Architectures in Automotive_ the Role of Standards, Methods and Tools.html:URL},
  keywords   = {Automotive engineering, Aerospace electronics, Computer architecture, Hardware, Software safety, Cost function, Software design, Design optimization, Software tools, Time factors, Architecture, automotive electronic system, automotive software, design methodology, design space exploration, system design},
  shorttitle = {Moving {From} {Federated} to {Integrated} {Architectures} in {Automotive}},
  url        = {https://ieeexplore.ieee.org/document/5440059},
  urldate    = {2024-06-06},
}

 
@Misc{Amend2017,
  author       = {James M. Amend},
  howpublished = {Webpage},
  month        = sep,
  title        = {Delphi {Automotive} {\textbar} {Suppliers} {Sees} {Shift} to {Centralized} {Computing}},
  year         = {2017},
  abstract     = {Delphi Automotive sees shift to centralized computing in vehicles from hundreds of individual electronic control units, partners with startup Renovo.},
  language     = {en},
  url          = {https://www.wardsauto.com/suppliers/delphi-industry-must-go-digital-or-die},
  urldate      = {2024-06-07},
}

 
@Article{Schaertel2022,
  author    = {Schärtel, Lukas and Reick, Benedikt and Pfeil, Markus and Stetter, Ralf},
  journal   = {Applied Sciences},
  title     = {Analysis and {Synthesis} of {Architectures} for {Automotive} {Battery} {Management} {Systems}},
  year      = {2022},
  issn      = {2076-3417},
  month     = jan,
  number    = {21},
  pages     = {10756},
  volume    = {12},
  abstract  = {Current batteries of battery electric vehicles (BEVs) require a battery management system (BMS) in order to enable a safe and long-lasting operation. The main functions of the battery management systems are a continuous monitoring of the voltage of each cell, a continuous monitoring of the battery temperature, the control of the charge current and the discharge current as well as the prevention of both a deep discharge and an overcharging. For the realization of these functions, different architectures are possible, ranging from an individual intelligent system at each cell up to a realization of the whole BMS within one central computing unit for the whole vehicle. This paper investigates and structures different architectural possibilities, discusses analysis possibilities and presents approaches for the synthesis of sensible architectures such as BMS. A concept synthesis for the start-up and shut-down of the high-voltage system is presented by comparing three different integrated pre- and discharging circuits and using a Hardware-in-the-Loop (HiL) program as an example. Finally, a topology consisting of three switches and two resistors (3S2R2) turns out to be the best one, due to the number of components, safety and price.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  doi       = {10.3390/app122110756},
  file      = {:Schaertel2022 - Analysis and Synthesis of Architectures for Automotive Battery Management Systems.pdf:PDF},
  keywords  = {battery management system, BMS, vehicle electronics, E/E-architecture},
  language  = {en},
  publisher = {Multidisciplinary Digital Publishing Institute},
  url       = {https://www.mdpi.com/2076-3417/12/21/10756},
  urldate   = {2024-06-10},
}

 
@InProceedings{Haas2016,
  author    = {Haas, Waldemar and Langjahr, P.},
  booktitle = {16. {Internationales} {Stuttgarter} {Symposium}},
  title     = {Cross-domain vehicle control units in modern {E}/{E} architectures},
  year      = {2016},
  address   = {Wiesbaden},
  editor    = {Bargende, Michael and Reuss, Hans-Christian and Wiedemann, Jochen},
  pages     = {1619--1627},
  publisher = {Springer Fachmedien},
  abstract  = {The complexity of E/E systems increases because of many new functionalities interacting across domain boundaries as for example in the area of automated driving and parking and powertrain electrification.},
  doi       = {10.1007/978-3-658-13255-2_118},
  file      = {:Haas2016 - Cross Domain Vehicle Control Units in Modern E_E Architectures.pdf:PDF},
  isbn      = {9783658132552},
  keywords  = {Control Unit, Automate Driving, Electronic Control Unit, Adaptive Cruise Control, Advanced Driver Assistance System},
  language  = {en},
}

 
@Misc{continental2024,
  author       = {continental},
  howpublished = {website},
  title        = {Vehicle {Domain}},
  year         = {2024},
  abstract     = {Vehicle Domains A vehicle domain describes the grouping of systems and functions in a vehicle that can be assigned to individual areas. The way in which the individual systems, components and the resulting functions are implemented are implemented using the appropriate architecture. In practice, the term vehicle domains is used synonymously for a modular group […]},
  journal      = {Continental Engineering Services},
  language     = {en-US},
  url          = {https://conti-engineering.com/areas-of-expertise/other-industries/vehicle-domain/},
  urldate      = {2024-06-14},
}

 
@InProceedings{Chou2023,
  author    = {Chou, Yuan-Hsiu and Li, Wen-Wei},
  booktitle = {2023 {IEEE} 12th {Global} {Conference} on {Consumer} {Electronics} ({GCCE})},
  title     = {Enhancing {OTA} {Update} {Security} in {Zonal} {Architecture} for {Automobiles}},
  year      = {2023},
  month     = oct,
  note      = {ISSN: 2693-0854},
  pages     = {761--762},
  abstract  = {Since the automobile industry enhances driving safety features and caters to increasing demands for driver entertainment, in order to reduce the time and cost of automobile software/firmware updates, the Over-The-Air (OTA) updates play a vital role. Any malicious updates or update failures, however, can pose significant personal safety risks. Hence, OTA updates in vehicular systems have emerged as a critical area of research. While some studies have explored secure transmission protocols between OTA Cloud and vehicles [1] , [2] , the secure flow of update packages towards the target components remains unaddressed. This paper aims to mitigate these security threats in vehicular update processes. We first examine the structure of the In Vehicle Network (IVN) in future automobiles, then establish an update threat model using STRIDE. Drawing upon international standards for vehicular software updates such as UNECE R156 and ISO 24089, we design security mechanisms for in-vehicle components, ensuring confidentiality, integrity, and authenticity of the update process. Moreover, we use the Two Phase Commit mechanism to ensure update atomicity within zonal architecture.},
  doi       = {10.1109/GCCE59613.2023.10315400},
  file      = {:Chou2023 - Enhancing OTA Update Security in Zonal Architecture for Automobiles.html:URL},
  issn      = {2693-0854},
  keywords  = {Threat modeling, Protocols, Software architecture, Computer architecture, Software, Safety, Security},
  url       = {https://ieeexplore.ieee.org/document/10315400},
  urldate   = {2024-06-14},
}

 
@InProceedings{Heurtefeux2021,
  author    = {Heurtefeux, K. and Kumar, M. and Cassol, M.},
  title     = {New {Automotive} {E}/{E} architecture and how {TC4xx} enables it – {From} domain-based to zone-based approach},
  year      = {2021},
  month     = oct,
  pages     = {429--434},
  publisher = {VDI Verlag},
  doi       = {10.51202/9783181023846-429},
  file      = {:Heurtefeux2021 - New Automotive E_E Architecture and How TC4xx Enables It – from Domain Based to Zone Based Approach.pdf:PDF},
  isbn      = {9783180923840 9783181023846},
  language  = {de},
  url       = {https://elibrary.vdi-verlag.de/10.51202/9783181023846-429/new-automotive-e-e-architecture-and-how-tc4xx-enables-it-from-domain-based-to-zone-based-approach?page=1},
  urldate   = {2024-06-17},
}

 
@Article{Maier2023,
  author    = {Maier, Jonas and Reuss, Hans-Christian},
  journal   = {Energies},
  title     = {Design of {Zonal} {E}/{E} {Architectures} in {Vehicles} {Using} a {Coupled} {Approach} of k-{Means} {Clustering} and {Dijkstra}’s {Algorithm}},
  year      = {2023},
  issn      = {1996-1073},
  month     = jan,
  number    = {19},
  pages     = {6884},
  volume    = {16},
  abstract  = {Electromobility and autonomous driving has started a transformation in the automotive industry, resulting in new requirements for vehicle systems. Due to its functions, the electrical/electronic (E/E) architecture is one of the essential systems. Zonal E/E architecture is a promising approach to tackle this issue. The research presented in this paper describes a methodology for determining the optimal number of zones, the position of the zone control units (ZCU), and the assignment of electric components to these zones and ZCUs. Therefore, the design of the power supply and the wiring harness is essential. This approach aims to identify the most suitable system architecture for a given vehicle geometry and a set of electric components. For this purpose, the assignment of electric components is accomplished by k-means clustering, and Dijkstra’s algorithm is used to optimize the cable routing. As ZCUs will be the hubs for the in-vehicle data and information transport in zonal architectures, their position and their number are crucial for the architecture and wiring harness development. Simulations show a suitable zonal architecture reduces wiring harness length as well as weight and brings functional benefits. However, the number of zones must be chosen with care, as there may also be functional limitations.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  doi       = {10.3390/en16196884},
  file      = {Full Text PDF:https\://www.mdpi.com/1996-1073/16/19/6884/pdf?version=1695978212:application/pdf},
  keywords  = {E/E architecture, clustering, wiring harness, zonal architecture, zone control unit},
  language  = {en},
  publisher = {Multidisciplinary Digital Publishing Institute},
  url       = {https://www.mdpi.com/1996-1073/16/19/6884},
  urldate   = {2024-06-19},
}

@Comment{jabref-meta: databaseType:bibtex;}
