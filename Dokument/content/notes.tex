\subsection*{Motivation}
\begin{notes}
    \item Herausforderungen bei Verteiltem Rechnen auf Fahrzeugen:
    \begin{notes}
        \item Resourcenmanagement
        \item Netzwerk Konnektivität
        \item Sicherheit
        \item Privatsphäre
        \item Standardisierung
        \item Kompatibilität
    \end{notes}
\end{notes}

\subsection*{Stand der Technik}
\begin{notes}
    \item Cloud Computing
    \begin{notes}
        \item: Definition
        \item IT resourcen werden flexibel nach Bedarf zur Verfügung bereitgestellt
        \item Realisiert durch Rechenzentren, Kunden können Resourcen mieten anstatt eigene Server betreiben
        \item Resourcen sind von verschiednen Endgeräten erreichbar \cite{Sunyaev2020}
        \item Cloud kann öffentlich oder privat sein, privat für sensible Daten \cite{Ibrahim2021}
        \item Relevante Anwendungsfälle:
    \end{notes}
    \item Edge Computing
    \begin{notes}
        \item Daten entstehen in Endgeräten, Applikationen, die die Daten verarbeiten sind zunehmend ebenfalls in Endgeräten
        \item Beispiel Flugzeuge oder autonome Fahrzeuge, generieren Daten in Größe von mehreren Gb pro Senkunde \cite{Liu2019}
        \item Traditionell werden Daten in der Cloud ausgewertet und wieder an den Benutzer zur Verfügung gestellt, diese ist aber mit zusätzlichem Resourcenaufwand verbunden wegen lange Übertragungsstrecken. \cite{Perez2022} 
        \item Übertragung und Verarbeitung in der Cloud langsam/unmöglich wegen Bandbreite und Latenz
        \item Edge Computing ist das Konzept, dass anstatt zentrale Cloud Server, Daten zunehmend auf Endgeräten verarbeitet werden \cite{Shi2016}
        \item Edge bezeichnet Geräte zwischen Datenquellen und cloud server
        \item “a form of distributed computing in which processing and storage takes place on a set of networked machines which are near the edge, where the nearness is defined by the system’s requirements”  (ISO/IEC: Tr 30164:2020 - internet of things (iot) -edge computing. Tech. rep., ISO/IEC (2020))
        \item Motivation: Latenzreduzierung, unbenutzte Resourcen verwenden
        \item Anwendungsfälle:
        \begin{notes}
            \item Cloud Berechnungen auslagern
            \item Smart Home, Daten lokal auswerten statt alles in die Cloud laden
            \item Smart City
        \end{notes}
        \item Cloudlets
        \item Mobile Edge Computing
        \item Edge Computing Gateway
        \item Fog Computing
        \begin{notes} 
            \item Fog Computing: Eine Form von Edge Computing, zusätzliche Schicht zwischen Endgeräte und Cloud
            \item Edge Geräte kommunizieren mit Fog nodes, die wiederrum für die Kommunikation zwishen Edge und Cloud zuständig sind
            \item Fog nodes übernehmen Datenverarbeitung lokal, für nur Lokal benötigte Daten, Leiten nur relevante Daten an Cloud weiter
            \item Fog nodes können PC-s, raspberry PI-s, nano-server, micro-datenzentren sein. \cite{Mahmud2020}
            \item Beispiele:
            \begin{notes} 
                \item Iot for All
                \item FogFlow
            \end{notes}
        \end{notes}
        \item Mist Computing
        \begin{notes} 
            \item Datenverarbeitung direkt im Sensor.
            \item Erlaubt z.b. einfache Monitoringfunktionen direkt im Sensor
            \item Reduktion von benörigte Bandbreite und Rechenleistung in den übergeordneten Geräten
        \end{notes}
        \item Distributed Cloud
    \end{notes}
    \item Internet of Things \gls{IoT} (IoT) 
    \begin{notes}
        \item Internet of Things (Internet der Dinge) bezeichnet eindeutig identifizierbare Objekte und deren virtuelle repräsentation in interent-ähnliche Strukturen\cite{Jie2013} 
        \item IoT findet mittlerweile in fast allen Bereichen Anwendung
        \item Industrie: Produktionsanlagen, die durch vernetzte Systeme flexibel angepasst werden können (Beispiel: Produktvarianten)
        \item Smart Home: Sensoren und Aktoren im Haus vernetzen \cite{Wortmann2015}
    \end{notes}

    \item Security: \cite{Mahmud2020}
    \begin{notes}
        \item Container: \cite{Costa2022}
        \begin{notes}
            \item Abstraktionsebene zwischen Prozesse und OS
            \item Packt die Prozesse und deren Abhängigkeiten zusammen so dass sie einfach auf andere Systeme portiert werden können
            \item definiert schnittstelle
            \item Läuft als Teil des Betriebssystems
            \item Software kann auch "bare metal" oder in hypervisor virtuelle machine ausgeführt werden
        \end{notes}
        \item Hypervisor:
        \begin{notes}
            \item Virtuelle Machine manager
            \item Jede Anwendung läuft im eigenen virtuellen OS (guest)
            \item Anwendung hat ggf. keine Information darüber dass es in virtuellen Umgebung läuft
            \item jede Anwendung läuft getrennt in eigenem Runtime Umgebung
        \end{notes}
    \end{notes}
    \item Kommunikation
    \begin{notes}
        \item Punkt zu Punkt
        \item Client-Server
        \item Remote Procedure Call
        \item Message oriented Middleware
        \item Direct Data Access
        \item Peer to Peer
        \item Publish/Subscribe:
            \begin{notes}
                \item Modell für Nachrichtenbasierte Kommunikation \cite{MadeWirawan2018}
                \item Ereignisbasierte Kommunikation
                \item Teilnehmer kommunizieren indem sie Nachrichten mit bestimmte Themen veröffentlichen (Publisher), Empfänger können Themen abonnieren (Subscriber) und bekommen nur die abonnierte Nachrichten
                \item Kommunikation ist anonym
                \item Komponenten: Publisher, Broker, Subscriber
                \item Broker stellt Verbindungen zwischen Publisher und Subscriber her
                \item Broker speichert die Subscriptions (Abos)
                \item Weit verbreitete Implementierung: MQTT
                \item RTPS:
                \begin{notes}
                    \item Real Time Publish Subscribe
                    \item Kommunikation erfolgt ebenfalls über Themen
                    \item Kein Broker, Teilnehmeridentifizierung erfolgt zur Laufzeit dezentralisiert
                    \item Quality of Service parameter: Reliable writer speichert Sequenznummer der Nachrichten und kann erneut versenden bei Übertraugungsfehler, Best effort Writer hat diese Funktionalität nicht
                    \item Heartbeat message: writer gibt die verfügbaren nachrichten ID-s and
                    \item AckNack message: kommunikation von empfangenen und nicht erhaltenen Nachrichten
                \end{notes}
            \end{notes}
    \end{notes}
    \item Resourcenmanagement:
    \begin{notes}
        \item t
    \end{notes}
    \item Softwarearchitektur
    \item 
\end{notes}


\begin{notes}

    \item Kommunikation
    \begin{notes}
        \item Zertifikate (Public/Private Key)
        \item identitätsverschlüsselung
        \item Belohnung für bereitgestellte Rechenleistung
    \end{notes}
    \item Resourcenverteilung
    \begin{notes}
        \item Bestimmung der verfügbaren Rechenleistung 
        \item Optimierungsalgorythmen
        \item Stackelberg Model
    \end{notes}
    \item Publish Subscribe
    \begin{notes}
        \item 
        \item Optimierungsalgorithmen
        \item Stackelberg Model
    \end{notes}
    \item Softwarearchitektur in Fahrzeugen
   \begin{notes}
        \item RTOS
        \item Middle Layer (ROS, keine automotive alternative stand 2019)
        \item Cloud
    \end{notes}
\end{notes}

\begin{notes}
     \item 1
\end{notes}

\begin{notes}
\item Stand der Technik
    \begin{notes}

        \item Anwendungsfälle für Fahrzeuge:
            \begin{notes}
                \item Unbenutzte Rechenleistung von Hardware nutzen, autonome Fahrzeugen haben leistungsfähige Steuergeräte
                \item Auslagerung von Rechenaufgaben auf Fahrzeuge in der Umgebung mit freier Rechenkapazitäten
                \item Ausnutzung von Rechenleistung parkende Fahrzeuge
                \item Möglichkeit, die unbenutzte Rechenleistung zu Vermieten (wie cloud service)
            \end{notes}

    \end{notes}
    \item Konzept UNICARagil:
        \begin{notes}
            \item Modulare Systemarchitektur in allen Domänen 
            \item Fahrzeuge können flexibel auf verschiedene Anwendungen angepasst werden: Taxi, Privatfahrzeug, Shuttle, Cargo
            \item gemeinsamer mechanischer Platform
            \item Sensoren und Aktoren mit definierte Schnittstellen
            \item Alle Fahrzeuge vernetzt: untereinander, zur Cloud, Infobiene, Benutzer 
        \end{notes}
    \item Motivation:
    \begin{notes}
        \item Zunehmende digitalisierung in Arbeits- und Privatumfeld
        \item Cloud Dienste bereits sehr verbreitet
        \item steigende Zahl an vernetzte Endgeräte
        \item Daten entstehen an Endgeräten, verarbeitete Daten werden ebenfalls an Endgeräten benötigt
        \item Cloud basierte ansätze erfordern immer höhere Bandbreite und zentralisierte Rechenleistung
        \item Endgeräte haben immer höhere Rechenleistung, die oft unbenutzt bleibt
        \item So auch in Fahrzeugen, die wegen autonome Fahrfunktionen deutlich mehr rechenleistung bekommen
        \item Ungenutze Rechenleistung kann für externe Anwendungen zur verfügung gestellt werden
        \item Dezentralisierte Rechenleistung verringert physikalische Distanz zwischen Entstehung und Verarbeitung der Daten
        \item Einsparung an Bandbreite und zusätzliche Server Rechenleistung
    \end{notes}

    \item Konzept: \cite{Mahmud2020}
    \begin{notes}
        \item Applikation Architektur:
        \begin{notes}
            \item monolithische Architektur
            \begin{notes}
                \item Applikation beinhaltet alle operationen
                \item die gleiche Applikation kann mehrfach ausgeführt werden für parallele berechnungen
            \end{notes}
            \item Verteilt:
            \begin{notes}
                \item Modulbasiert:

                    \item Applikation auf Module aufgeteilt, abhängig voneinander
                    \item Bedienen Daten von einer Quelle
                    \item partitionierung von Applikationen \cite{Ashraf2022}
 
                \item Micro-Services:
                    \item Applikation setzt sich aus unabhängigen Prozessen zusammen
                    \item Ein Microservice erfüllt nur eine Aufgabe
            \end{notes}
        \end{notes}
        \item Applikation Platzierung: \cite{Mahmud2020}
        \begin{notes}
            \item Bestimmung verfügbare Rechenresourcen:
            \begin{notes}
                \item Profilierung: Applikation wird auf jedem Node ausgeführt, Rechenleistung wird aus Ausführungszeit bestimmt
                \item Prädiktiv: Rechenleistung wird aus vergangenen Berechnungen ermittelt
                \item Nach Bedarf: Je nach Erwartungen der Benutzer und Anforderungen an die Ausführungszeit wird nach Profil oder Prädiktiv verteilt
            \end{notes}
            \item Offloading Methoden:
            \begin{notes}
                \item Bottom-Up: Edge Geräte verlagern Applikationen in die Node Server
                \item Top-Down: Applikationen aus der Cloud oder Fog Node werden in Edge Geräte ausgelagert
                \item Hybrid: Top-Down, Bottom-Up, Edge geräte können Applikationen direkt untereinander austauschen
            \end{notes}
            \item Resourcenorientierung -Netzwerkstruktur
            \begin{notes}
                \item Hierarchie: Fog node server sind in Hierarchieebenen eingeteilt. Anzahl der Nodes auf einer Ebene nimmt nach unten hin zu. 
                \item Cluster: Fog nodes sind alle untereinander verbunden. Edge geräte werden in jeweilige Cluster gruppiert. Bessere horizontale Skalierung als bei Hierarchie.
                \item Client-Server: Einige Fog Nodes funktionieren als Server, die anderen als client. Client nodes leiten ihre daten an den server weiter.
                \item Master-Slave: Master node verteilt daten an slave nodes. Verwaltet die slave nodes. Master node kommuniziert die Ergebnisse.
            \end{notes}
            \item Mapping:
            \begin{notes}
                \item Prioritätsbasiert: Priorisiert app platzierung auf bestimmte fog nodes, meistens heuristische methoden (best fit, first fit). 
                \item Optimierung: Kostenfunktion für die optimale Aufteilung erstellen und optimieren
                \item multi-objective trade-off: nach mehreren Anforderungen gleichzeitig optimieren wie Energieverbrauch, verfügbarkeit, kosten
            \end{notes}
            \item Platzierung
            \begin{notes}
                \item Statisch: Applikation wird einmal für jede Applikation platziert
                \item dynamischen: Mehrere Instanzen einer Applikation können ausgeführt werden oder Applikation wird nur für eine Berechnung ausgeführt
                \item Ereignisbasiert: Applikation wird zur Laufzeit umgezogen
            \end{notes}
            \item Ausführungsumgebung:
            \begin{notes}
                \item Bare metal
                \item Virtuelle machine
                \item container: \cite{Costa2022}
                \item   weniger overhead als virtuelle maschine
                \item   verschiedene runtimes bereits verfügbar: Docker
                \item   Orchestrierungsmöglichkeiten verfügbar: Kubernetes, Docker Swarm, Nomad, Marathon, Mesos
                \item   Kontainerorchestrator ermöglicht Lebenszyklus, Skalierung, selbsthailung, migrierung, 
                \item   Docker als verbreitete Implmenetierung
            \end{notes}
            \item Platzierungskriterien:
            \begin{notes}
                \item Quality of Service
                \item Service level Agreement
                \item Zeit und deadline
                \item Profit
                \item User-erfahrung
                \item Kosten
                \item externe Vorgaben
                \item Energie
                \item verfügbarkeit
                \item Mobilität
            \end{notes}
        \end{notes}
        \item Applikationsverwaltung: \cite{Mahmud2020}
        \begin{notes}
            \item Fog Netzwerkverwaltung: \cite{Costa2022}
            \begin{notes}
                \item zentralisiert: fog orchestrator an zentraler Stelle. Hat gesamtüberblick über das Netzwerk
                \item dezentralisiert: 
                \item Verteilt:
            \end{notes}
            \item Safety:
            \begin{notes}
                \item Datenintegrität
                \item Verschlüsselung
                \item Authentifizierung
            \end{notes}
            \item Leistungsüberwachung
            \begin{notes}
                \item Implikationbasiert: 
                \item Grenzwertbasiert:
            \end{notes}
            \item Finanzielle Unterstützung
            \begin{notes}
                \item Kompensation: Bei Serviceausfall werden benutzer kompensiert
                \item Anreize: Verfügbare resourcen werden bei Bedarf zur verfügung gestellt, besitzer der Resourcen werden vergütet
                \item Reservierung: Verfügbare rechenleistung kann reserviert werden damit Verfügbarkeit garantiert wird
            \end{notes}
            \item resillienz:
            \begin{notes}
                \item Backup-Restore
                \item Verfielfachung
                \item Operator Migration
            \end{notes}
        \end{notes}
    \end{notes}
   
\end{notes} 

\begin{notes}
    \item Anforderungen:
    \begin{notes}
        \item Verfügbare Rechenleistung für externe Kunden zugänglich machen
        \item Kommunikationsmöglichkeit bieten, auch für parallele Berechnungen
        \item Resourcenmanagement
        \item Netwerküberwachung
        \item Quality of Service sicherstellen    
        \item Lebenszyklus verwalten
        \item Sicherheitsmaßnahmen vorsehen
        \item Buchhaltung über Angefragte und gelieferte Rechenleistung

        \item Verwaltungsdienst:
        \begin{notes}
            \item Kommunikationsschnittstelle für den Kunden
            \item Erkennung von Teilnehmern (edge devices)
            \item Informationen über die Fähigkeiten der Teilnehmer sammeln (Architektur, Rechenleistung, Verfügbarkeit, Latenz)
            \item Ermittung einer optimalen Verteilung von Kundenaufgaben an Teilnehmer
            \item Verteilung von Kundenapplikationen an geeignete Teilnehmer
            \item Kommunikationsschnittstelle zu den verteilten Kundenapps
            \item Kommunikationsschnittstelle für den Kunden
            \item Datenbank über Angeforderte und geleistete Berechnungen
            \item Vergütungsausschüttung nach Leistung
        \end{notes}
        \item Loader Applikation:
        \begin{notes}
            \item Meldet verfügbarkeit an Verwaltungsdienst
            \item Meldet Architektur, Rechenleistung, Verfügbarkeit an Verwaltungsdienst
            \item Bietet Kommunikationsschnittstelle für die Übertraung von komppilierten Kundenapps
            \item Bietet Kommunikationsschnittstelle für die Kommunikation mit Kundenapplikationen
            \item Bietet Kommunikationsschnittstelle für die Verwaltung durch Verwaltungsdienst
            \item Richtet Laufzeitumgebung für Kundenapplikation ein
            \item Zugriffsrechte der Kundenapplikation werden eingeschränkt
            \item Kann Kundenapplikation starten und beenden
            \item Kommuniziert Applikationsstatus an Verwaltung
        \end{notes}
    \end{notes}
    \item Netzwerkstruktur:
    \begin{notes}
        \item Autotechagil Struktur gegeben: Cloud: Leitwarte, Edge device: Fahrzeuge, Infobiene
        \item Zentraler Struktur bietet sich an: Leitwarte auch Fog Orchestrator
        \item 
    \end{notes}
\end{notes}

\begin{notes}
    \item Container Interface (OCI kompatibilität):
    \begin{notes}
        \item Create
        \item Start
        \item State
        \item Kill
        \item Delete
    \end{notes}
    \begin{notes}
        \item JSON Varianten:
        \item    
        \item     
    \end{notes}
    \item Container Parameter:
    \begin{notes}
        \item Stack size
        \item Distroless
        \item 
    \end{notes}
\end{notes}

\begin{notes}
    \item Einleitung
    \begin{notes}
        \item Bestrebung für höhere Resourceneffizienz
        \item Bevölkerungsentwicklung
        \item Entwicklung autonome Fahrzeuge
        \item Ziele und Aufbau der Arbeit
    \end{notes}    
    \item Stand der Technik
    \begin{notes}
        \item Einleitung Cloud Computing und verteiltes Rechnen
        \item Cloud Computing Stand der Technik
        \item Distributed Computing Stand der Technik
        \item Beschreibung Management Tools 
        \item Container
        \item Virtual Machine
        \item Applikationen:
        \item Docker
        \item Kubernetes
        \item Verteiltes Rechnen im Fahrzeug
        \item keine praktische Umsetzung, Konzepte vorführen
    \end{notes}
    \item Forschungsansatz
    \begin{notes}
        \item Anforderungen festlegen für Einsatz im Fahrzeug
        \item Defizite der vorhandenen Lösungen ermitteln
        \item 
    \end{notes}
    \item Applikationserwaltung im Fahrzeug
    \item Applikationsverwaltung im Fahrzeugnetzwerk
    \item Kommunikation und Sicherheit
    \item Validierung
    \item Zusammenfassung
\end{notes}

% https://www.eprosima.com/index.php?option=com_ars&view=browses&layout=normal